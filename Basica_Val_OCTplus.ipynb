{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02707f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#########################################################################################################################\n",
    "INFORMACIÓN DEL FICHERO\n",
    "#########################################################################################################################\n",
    "\n",
    "Autor: Samuel Lozano Juárez\n",
    "Fecha: 24/05/2023\n",
    "Institución: UBU | Grado en Ingeniería de la Salud\n",
    "\n",
    "Este archivo forma parte del Trabajo de Fin de Grado \"Detección del grado de retinopatía mediante redes convolucionales\".\n",
    "El alumno a cargo de este proyecto es el declarado como autor en las líneas anteriores.\n",
    "Los tutores del proyecto fueron el Dr. Darío Fernández Zoppino y el Dr. Daniel Urda Muñoz.\n",
    "\n",
    "En el código que se encuentra a continuación voy a crear una primera arquitectura de red neuronal convolucional, así como las demás \n",
    "estructuras necesarias para poder entrenar dicha red (como por ejemplo las funciones que permiten cargar las imágenes o generar los \n",
    "batches o lotes para el entrenamiento).\n",
    "\n",
    "El entrenamiento de la red se llevará a cabo empleando un conjunto de validación para poder aplicar la estrategia de Early Stopping y evitar el sobreentrenamiento.\n",
    "\n",
    "Para entrenar los modelos se usarán imágenes de OCT + Samsung o iPhone y se testearán con el conjunto de imágenes no empleado en el entrenamiento (iPhone o Samsung respectivamente).\n",
    "\n",
    "La arquitectura del modelo será básica, siguiendo la estructura que se encuentra disponible en la propia página del framework Pytorch:\n",
    "https://pytorch.org/tutorials/beginner/introyt/introyt1_tutorial.html#pytorch-models\n",
    "\n",
    "Finalmente se obtendrán las métricas de Accuracy, Balanced Accuracy, F-Score, AUC de la curva ROC y Quadratic Weighted Kappa, tanto para\n",
    "imágenes de iPhone como imágenes de Samsung. De esta manera podremos evaluar el rendimiento de la red en comparación con un clínico.\n",
    "'''\n",
    "\n",
    "#primero importamos todos los paquetes necesarios\n",
    "import torch #contiene todas las funciones de PyTorch\n",
    "import torch.nn as nn #contiene la clase padre de todos los modelos (nn.Module)\n",
    "import torch.nn.functional as F #esencial para la función de activación \n",
    "import torchvision #fundamental para la importación de imágenes\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from matplotlib import pyplot as plt #para poder representar las gráficas\n",
    "import numpy as np #para las métricas de la red\n",
    "\n",
    "#importamos también las funciones definidas para el entrenamiento y puesta a prueba de los modelos\n",
    "from modules.CNN_utilities import entrena_val, representa_test, obtiene_metricas, tester, guarda_graficas\n",
    "\n",
    "#importamos el paquete que permite calcular el tiempo de entrenamiento\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be88f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establecemos el tamaño del batch, la escala de las imágenes y el número de épocas de entrenamiento\n",
    "batch = 4\n",
    "escala = 640\n",
    "epocas = 150 #ya que tenemos activado Early Stopping\n",
    "\n",
    "#a continuación definimos la operación que permitirá transformar las imágenes del repositorio en Tensores que puedan ser empleados por PyTorch\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), #transforma la imagen de formato PIL a formato tensor\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), #normaliza el tensor para que la media de sus valores sea 0 y su desviación estándar 0.5\n",
    "     transforms.Resize((escala, escala))]) #redimensionamos las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f476b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMENZAMOS CON LOS ELEMENTOS NECESARIOS PARA EL ENTRENAMIENTO CON SAMSUNG Y TEST CON IPHONE\n",
    "#primero definimos una lista con las rutas de los directorios que queremos combinar (OCT + Samsung)\n",
    "root_dirs_OCT_S = ['Datos/Classified Data/Images/Samsung/No_inpaint', 'Datos/Classified Data/Images/OCT']\n",
    "#inicializamos una lista 'datasets_OCT_S' vacía que almacenará las imágenes y etiquetas\n",
    "datasets_OCT_S = []\n",
    "#recorremos los directorios a concatenar\n",
    "for root_dir in root_dirs_OCT_S:\n",
    "    #cargamos las imágenes (y etiquetas correspondientes) de dichos directorios, con la transformación aplicada\n",
    "    dataset = ImageFolder(root_dir, transform = transform)\n",
    "    #añadimos esas imágenes y etiquetas a la lista previamente creada\n",
    "    datasets_OCT_S.append(dataset)\n",
    "\n",
    "#concatenamos esas imágenes y mostramos el tamaño total del dataset de entrenamiento\n",
    "OCT_S = ConcatDataset(datasets_OCT_S)\n",
    "print(f'Tamaño del conjunto de datos de train: {len(OCT_S)}')\n",
    "\n",
    "#cargamos el dataset de test y mostramos su tamaño\n",
    "iPhone = ImageFolder(root = 'Datos/Classified Data/Images/iPhone/No_inpaint', transform = transform)\n",
    "print(f'Tamaño del conjunto de datos de test de iPhone: {len(iPhone)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf29f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#en esta ocasión, debido a que vamos a implementar EarlyStopping es necesario dividir el conjunto de entrenamiento en train y validation\n",
    "#Dividimos el conjunto de datos en entrenamiento y validación (80% y 20% respectivamente)\n",
    "train_size = int(0.8 * len(OCT_S))\n",
    "val_size = len(OCT_S) - train_size\n",
    "train_dataset_OCT_S, val_dataset_OCT_S = torch.utils.data.random_split(OCT_S, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalmente creamos los objetos DataLoader correspondientes (de entrenamiento, validación y test con iPhone)\n",
    "#primero el DataLoader de entrenamiento\n",
    "train_loader_OCT_S = DataLoader(\n",
    "    train_dataset_OCT_S, #indicamos el conjunto de imágenes combinadas de entrenamiento\n",
    "    batch_size=batch,\n",
    "    shuffle=True, #mezclamos las imágenes para combinar de todos los grados y fuentes en cada batch\n",
    "    num_workers = 2 #así genera subprocesos y acelera la alimentación del modelo con imágenes\n",
    ")\n",
    "\n",
    "#posteriormente definimos el DataLoader de validación\n",
    "val_loader_OCT_S = DataLoader(\n",
    "    dataset = val_dataset_OCT_S, #indicamos el conjunto de imágenes combinadas de validación\n",
    "    batch_size = batch,\n",
    "    shuffle = True, #mezclamos las imágenes para combinar de todos los grados y fuentes en cada batch\n",
    "    num_workers = 2 #así genera subprocesos y acelera la alimentación del modelo con imágenes\n",
    ")\n",
    "\n",
    "#y finalmente el DataLoader de test con las imágenes de iPhone\n",
    "test_i_loader = DataLoader(\n",
    "    dataset = iPhone,\n",
    "    batch_size = batch,\n",
    "    shuffle = True, #mezclamos las imágenes para combinar de todos los grados y fuentes en cada batch\n",
    "    num_workers = 2 #así genera subprocesos y acelera la alimentación del modelo con imágenes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AHORA REALIZAMOS EL MISMO PROCESO PERO PARA ENTRENAR EL MODELO CON IPHONE Y HACER EL TEST CON SAMSUNG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
