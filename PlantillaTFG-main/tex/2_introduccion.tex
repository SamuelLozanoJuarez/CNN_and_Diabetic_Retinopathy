\capitulo{2}{Introducción} \label{Intro}

\setlength{\parskip}{10pt}

Una de las ventajas que presentan titulaciones como Ingeniería de la Salud es la capacidad para desarrollar proyectos interdisciplinares, es decir, que aúnen técnicas y conocimientos de diversos campos. Ejemplo de ello es el trabajo recogido en esta memoria, ya que en él convergen ideas pertenecientes al ámbito sanitario, biológico y computacional.

Este tipo de iniciativas son capaces de abrir nuevos campos de investigación, ampliar las perspectivas y mejorar la eficiencia en la resolución de problemas. Sin embargo, estas propuestas generalmente son complicadas de entender en su totalidad, debido a la heterogeneidad de conceptos abarcados.

Es por ello que en las siguientes secciones y subsecciones se van a explicar los fundamentos informáticos y fisiológicos esenciales para poder entender el proyecto, independientemente del ámbito al que pertenezca el lector, así como la estructura de la memoria y del resto de materiales entregados.

\titlespacing{\section}{0pt}{0.25cm}{0.15cm}
\section{Estructura de la memoria}

En este documento y sus correspondientes anexos se recoge toda la información del proyecto \textit{Detección del grado de retinopatía diabética mediante redes convolucionales}.

En la memoria principal se incluyen los capítulos detallados en el \hyperref[toc]{Índice}: \hyperref[Obj]{Objetivos}, \hyperref[Intro]{Introducción}, \hyperref[Met]{Metodología}, \hyperref[Conc]{Conclusiones} y \hyperref[Fut]{Líneas futuras}. Además se incluye la correspondiente bibliografía en la que se citan todas las fuentes empleadas en el proyecto.

Asimismo se entrega una memoria de anexos, que contiene materiales adicionales y ampliaciones de los contenidos de la memoria principal.

Todos los materiales empleados en el proyecto, incluyendo el código \LaTeX de las memorias, los scripts de Python para la creación y entrenamiento de modelos, y las imágenes empleadas en el entrenamiento, pueden encontrarse en el siguiente repositorio de GitHub: \href{https://github.com/SamuelLozanoJuarez/CNN_and_Diabetic_Retinopathy}{CNN and Diabetic Retinopathy}.

\titlespacing{\section}{0pt}{0.25cm}{0.15cm}
\section{Conceptos teóricos básicos}

A continuación se van a explicar los conceptos teóricos fundamentales sobre la retinopatía diabética y las redes neuronales convolucionales, necesarios para entender el contexto en que se desarrolla este proyecto.

\titlespacing{\subsection}{0pt}{0.25cm}{0.15cm}
\subsection{Retinopatía diabética}

La retinopatía diabética (RD) es la complicación más común de la diabetes mellitus (DM), y constituye una de las principales causas de ceguera en edad avanzada \cite{diabetes:JDI, retinopatia:Retinal_and_eye}. Se trata de una microangiopatía diabética, una patología que afecta a los capilares que irrigan la retina, como consecuencia de los altos niveles de glucosa en sangre \cite{retinopatia:chile}.

Esta enfermedad se desarrolla en más de una quinta parte de los individuos diagnosticados con DM a nivel global, siendo esta proporción mayor en la región de América del Norte. En números brutos estamos hablando de más de 100 millones de personas que padecen esta afección en todo el mundo \footnote{Los datos se corresponden al año 2020.} \cite{retinopatia:ophtalmology}.

A pesar de que existen tratamientos que permiten ralentizar, e incluso revertir, la evolución de la enfermedad, estos presentan una mayor eficacia en las primeras etapas de desarrollo de la RD, por lo que un diagnóstico temprano es fundamental a la hora de preservar la visión del paciente \cite{diabetes:JDI}.

\titlespacing{\subsubsection}{0pt}{0.25cm}{0.1cm}
\subsubsection{Epidemiología}

La prevalencia mundial de la DM en individuos entre 20 y 80 años en el año 2021 fue del 10,5\%, lo que supone un total 536,3 millones de personas diagnosticadas con esta patología en esa franja de edad. Sin embargo, lo realmente preocupante es el pronóstico ofrecido por la Federación Internacional de Diabetes, que estima que esta prevalencia aumentará hasta alcanzar el 12,2\% en el año 2045, involucrando a 783,2 millones de personas \cite{diabetes:IDF}.

La RD es la complicación más común de la DM, y constituye la primera causa de pérdida de visión y ceguera evitable en adultos entre 20 y 74 años, especialmente en los países de ingresos medios-altos \cite{retinopatia:lancet}. En el año 2020, la prevalencia mundial de la RD entre pacientes diagnosticados con DM fue del 22,27\%, afectando a 103,12 millones de personas. Se prevé que este valor aumente hasta los 160,5 millones de personas para el año 2045 \cite{retinopatia:ophtalmology}.

Aunque se sospecha que la prevalencia de la RD no es igual entre los pacientes diagnosticados con DM tipo 1 y tipo 2, lo cierto es que no hay estudios suficientes a nivel global que permitan respaldar esta sospecha \cite{retinopatia:ophtalmology}, aunque sí se ha observado una mayor prevalencia entre los pacientes de DM tipo 1 frente a los pacientes de DM tipo 2 dentro de la cohorte europea \cite{retinopatia:por_tipos}. 

No se han encontrado estudios que recojan información acerca de la incidencia global de la RD. Entre los años 1996 y 2017 en Europa la incidencia anual de la RD en pacientes con DM de tipo 2\footnote{Todos los estudios encontrados acerca de la incidencia en Europa consideraban únicamente los pacientes con DM tipo 2, debido a que constituyen la mayor parte de los pacientes con DM.} fue del 4,6\% \cite{retinopatia:por_tipos}, mientras que la incidencia anual en España entre los años 2001 y 2020 en pacientes con DM de tipo 2\footnote{Se ha incluido la incidencia únicamente de pacientes con DM tipo 2 para facilitar la comparación con el equivalente europeo y debido a que estos representan casi la totalidad de pacientes con DM. El valor de la incidencia anual entre los años 2007 y 2014 en España en pacientes con DM de tipo 1 y 2 fue de 8,99\% \cite{retinopatia:espana}} fue del 3,83\% \cite{retinopatia_review:espana}.

\titlespacing{\subsubsection}{0pt}{0.25cm}{0.1cm}
\subsubsection{Fisiopatología y manifestaciones clínicas}

La RD es una complicación microvascular de la DM, más concretamente se trata de una patología que aparece como consecuencia del desarrollo de una microangiopatía diabética. Si bien no se conoce la causa exacta de esta microangiopatía, la teoría más aceptada es que la hiperglicemia provocada por la diabetes induce un aumento del sorbitol intracelular (un poliol) \cite{retinopatia:cheung}. Este incremento de sorbitol, combinado con un mayor estrés oxidativo, produce un deterioro de los pericitos, las células que actúan como barrera hematoretinal \cite{retinopatia:chile}.

Como consecuencia de este daño se pueden producir roturas de los capilares que irrigan la retina, exudados lipídicos, edemas  y filtraciones en el espacio extravascular, así como la formación de microaneurismas (un abombamiento de los capilares) y trombos capilares, conduciendo a la pérdida de irrigación sanguínea en determinadas zonas de la retina. Estas pérdidas serán responsables de la producción de isquemia retinal, neovascularización (formación de nuevos vasos sanguíneos inducida por el Factor de Crecimiento Vascular Endotelial (VEGF)) e incluso desprendimiento de retina y, en definitiva, ceguera \cite{retinopatia:chile,retinopatia:cheung}. 

Uno de los grandes peligros que entraña la RD es que la mayoría de pacientes que desarrollan esta complicación no presentan síntomas hasta que el estado ya es avanzado \cite{diabetes:JDI}. Entre estas manifestaciones clínicas, las más habituales son la aparición de puntos oscuros en el campo visual, la visión borrosa, problemas para detectar los colores o directamente la ceguera \cite{retinopatia:sintomas}. Por supuesto, debemos tener en cuenta que estos síntomas deben cursar con una DM.

Se ha de tener mayor atención (jugando un papel crucial el diagnóstico y las pruebas rutinarias) siempre que el paciente presente alguno de los factores de riesgo más habituales, como la hiperglicemia, hipertensión o hiperlipemia \cite{diabetes:JDI}. Además se ha demostrado que el riesgo de sufrir RD incrementa conforme aumenta el tiempo de duración de la diabetes, de manera que el 97,5\% de los pacientes con DM tipo I y el 77,8\% de pacientes con DM tipo II padecen algún tipo de RD después de 15 años \cite{retinopatia:chile}.

\titlespacing{\subsubsection}{0pt}{0.25cm}{0.1cm}
\subsubsection{Diagnóstico}

Como se ha mencionado en el apartado anterior, la mayoría de pacientes son asintomáticos hasta que la enfermedad se encuentra ya en un estado avanzado, por lo que una detección precoz de la RD puede suponer la diferencia entre perder o no la visión \cite{diabetes:JDI}.

El principal procedimiento de diagnóstico es el examen de fondo de ojo \cite{retinopatia:Retinal_and_eye}, también denominado OCT por sus siglas en inglés (\textit{Optical Coherence Tomography}) \cite{retino:OMS}, que se basa en la toma de una fotografía de la retina a través de la pupila (que puede estar dilatada o no), para que posteriormente esa imagen sea evaluada por un equipo de oftalmólogos. La imagen debe ser tomada usando un dispositivo apropiado (denominado cámara de \textit{fundus} o retinógrafo) \cite{retino:tecnica_fundus}. En la figura \ref{fig:partes_retina} se puede observar una imagen de fondo de ojo con las distintas partes que se distinguen en la retina.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{img/partes_retina.png}
    \caption{Fondo de ojo de un paciente sano. Señalado en color amarillo se puede observar el nervio óptico, en color verde la mácula, en rojo las venas y en azul las arterias. Dentro de la mácula se encuentra la fóvea, señalada en color blanco. Fuente propia.}
    \label{fig:partes_retina}
\end{figure}

En pacientes con DM tipo 2, el examen de fondo de ojo debe realizarse tan pronto como la diabetes es diagnosticada, mientras que en pacientes con DM tipo 1 este examen debe realizarse por primera vez transcurridos 5 años desde el diagnóstico de la diabetes \cite{diabetes:JDI}. En el caso de niños que desarrollen diabetes prepuberal es recomendable un primer examen de fondo de ojo al alcanzar la pubertad \cite{retinopatia:cheung}. Una vez llevado a cabo el primer examen, la frecuencia con que se realice esta prueba diagnóstica dependerá de cada paciente, empleándose en ocasiones algoritmos matemáticos para poder estimar los intervalos entre estas sesiones \cite{retinopatia:Retinal_and_eye}.

Para llevar a cabo el diagnóstico, el oftalmólogo responsable evalúa la imagen del fondo de ojo en busca de microaneurismas, exudados, hemorragias y neovascularizaciones. Estos signos permitirán al especialista determinar si el paciente tiene o no RD y, en caso de tener, clasificar la severidad de la enfermedad \cite{retino:OMS}. 

Aunque la realización de exámenes de fondo de ojo ha demostrado tener un balance coste-efectividad positivo \cite{retinopatia:Retinal_and_eye}, la realidad es que la periodicidad con que se realizan estas pruebas no sigue los patrones recomendados. Para que nos hagamos una idea, el 40\% de los pacientes con DM en EE.UU., o el 38\% en Canadá, no están siendo  examinados según las recomendaciones anuales \cite{retin:eeuu, retin:canada}.

Para tratar de poner solución a este problema se están comenzando a emplear estrategias basadas en la telemedicina, que permitan realizar estos exámenes de manera remota \cite{retino:telemedicina}. Además, estas nuevas vías de diagnóstico pueden reducir, para determinados casos, las listas de espera a las que pueden verse sometidos los pacientes antes de ser evaluados por los especialistas. La implementación de la telemedicina es especialmente útil en las zonas rurales, donde los servicios pueden ser más escasos y los pacientes deben desplazarse grandes distancias para poder realizar los exámenes correspondientes \cite{retino:rural}.

Es en este contexto donde cobra mayor sentido el proyecto que he desarrollado. Con el objetivo abrir nuevas vías de telemedicina, el Dr. Ian Roberts, actualmente oftalmólogo en el Hospital Universitario de Burgos, desarrolló en 2019 un dispositivo denominado \textit{Ret-iN CaM} (figura \ref{fig:retincam_dispositivo}) que permitía tomar fotografías de fondo empleando un teléfono móvil. La ventaja que esto supone radica en que la fotografía no tendría que ser tomada en la consulta del especialista, sino que podría ser obtenida por el médico de familia y analizada por el especialista (o por un modelo de inteligencia artificial como el desarrollado en este trabajo).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{img/retincam dispositivo.jpg}
    \caption{Dispositivo Ret-iN CaM. Permite tomar fotografías de fondo de ojo empleando un dispositivo móvil. Fuente propia.}
    \label{fig:retincam_dispositivo}
\end{figure}

Las imágenes de fondo de ojo adquiridas mediante este instrumento son las empleadas en el proyecto para poner a prueba las redes neuronales convolucionales desarrolladas. En la figura \ref{fig:retincam_oct} se puede observar un ejemplo de uso de este dispositivo en comparación con el instrumento empleado para la realización de un examen de fondo de ojo habitual.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{img/retincam_oct.png}
    \caption{Izquierda: profesional tomando una imagen de fondo de ojo mediante tomografía de coherencia óptica \cite{retino:OMS}. Derecha: profesional empleando el dispositivo Ret-iN CaM para adquirir una fotografía de fondo de ojo. Fuente propia.}
    \label{fig:retincam_oct}
\end{figure}

\titlespacing{\subsubsection}{0pt}{0.25cm}{0.1cm}
\subsubsection{Clasificación}

La clasificación de la RD se realiza en base a la severidad de los daños vasculares que presente el paciente. Actualmente el estándar de clasificación empleado es el establecido en el Estudio sobre el Tratamiento Precoz de la Retinopatía Diabética (ETDRS), que se basa en las características anatómicas de la retina y el número de lesiones vasculares para establecer los distintos grados \cite{retino:etdrs, retinopatia:Retinal_and_eye}. 

La RD puede clasificarse, a grandes rasgos, en dos niveles en función de la degeneración microvascular y el daño isquémico: retinopatía diabética no proliferativa (NPDR por sus siglas en inglés) y retinopatía diabética proliferativa (PDR por sus siglas en inglés). La principal diferencia entre ambos niveles es que en la NPDR no se produce neovascularización y los daños se limitan a la retina, mientras que en la PDR se generan nuevos vasos sanguíneos que proliferan más allá de la retina \cite{retinopatia:chile,retinopatia:cheung}. 

La NPDR a su vez se puede dividir en 3 niveles: leve, moderada y severa. Por tanto, finalmente podemos distinguir 5 posibles niveles de RD: paciente sano, NPDR leve, NDPDR moderada, NPDR severa y PDR. A continuación se describen algunas de los signos que caracterizan a cada nivel \cite{retinopatia:cheung, retino:OMS}:

\begin{itemize}[itemsep=0.25em]
    \item \textbf{Sano}. No se observan lesiones vasculares ni exudados (figura \ref{fig:G0}).

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{img/G0.png}
        \caption{Fondo de ojo de individuo sano. Fuente propia.}
        \label{fig:G0}
    \end{figure}
    
    \item \textbf{NPDR leve}. Presencia de microaneurismas en la retina (únicamente, sin exudados ni hemorragias) (figura \ref{fig:G1}).

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{img/G1.png}
        \caption{Fondo de ojo de paciente con NPDR leve. Fuente propia.}
        \label{fig:G1}
    \end{figure}
    
    \item \textbf{NPDR moderada}. Se observan microaneurismas además de exudados, pequeñas hemorragias y obstrucción de algunos capilares (figura \ref{fig:G2}).

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{img/G2.png}
        \caption{Fondo de ojo de paciente con NPDR moderada. Fuente propia.}
        \label{fig:G2}
    \end{figure}

    \item \textbf{NPDR severa}. Presenta más de 20 hemorragias en cada uno de los 4 cuadrantes en que se divide la retina, rosario venoso (estenosis y dilatación de los capilares) en al menos 2 cuadrantes y anormalidades microvasculares, todo ello en ausencia de neovascularización (figura \ref{fig:G3}).

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{img/G3.png}
        \caption{Fondo de ojo de paciente con NPDR severa. Fuente propia.}
        \label{fig:G3}
    \end{figure}
    
    \item \textbf{PDR}. El signo más característico es la neovascularización (aparición de nuevos vasos sanguíneos frecuentemente cerca del nervio óptico) junto con hemorragias, rosario venoso y demás características presentes también en la NPDR severa (figura \ref{fig:G4}).

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{img/G4.png}
        \caption{Fondo de ojo de paciente con PDR. Fuente propia.}
        \label{fig:G4}
    \end{figure}
    
\end{itemize}

\subsection{Redes Neuronales Convolucionales}

Las redes neuronales convolucionales (CNN por sus siglas en inglés) son un tipo de redes neuronales especializadas en el reconocimiento de patrones, tanto en imágenes como en señales, inspiradas por el mecanismo natural de percepción visual de los seres vivos \cite{cnn:gu, cnn:ieee}. Fueron descritas por primera vez en 1989 por Le-Cun et. al \cite{cnn:antecesor} y desde esa fecha han ido evolucionando y perfeccionándose hasta desarrollar algunos de los modelos más sofisticados que podemos encontrar a día de hoy (VGGNet o ResNet en sus distintas versiones) \cite{cnn:gu}. 

Una de las características de estos modelos, que los han hecho tan populares, es la reducción de parámetros lograda con respecto a otras arquitecturas de redes neuronales, permitiendo así desarrollar modelos más complejos y de mayor tamaño \cite{cnn:ieee}.

\subsubsection{Redes Neuronales}

Las redes neuronales artificiales (ANN por sus siglas en inglés) son modelos matemáticos, computacionales, que tratan de simular la estructura y funcionamiento de las neuronas biológicas \cite{cnn:osea}. El componente básico de una ANN es la neurona artificial, una función matemática con un comportamiento característico. Una neurona artificial recibe como entrada una serie de valores numéricos, siendo cada uno de ellos multiplicado por un peso concreto. Posteriormente, en el interior de la neurona se produce la suma de todos esos valores (multiplicados por su correspondiente peso). Finalmente esa suma pasa a través de una función de activación (o función de transferencia) que proporciona el valor que devolverá la neurona como salida \cite{ann:intro}. Este funcionamiento puede observarse resumido en la figura \ref{fig:neurona}.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{img/neurona.png}
    \caption{Funcionamiento básico de una neurona artificial \cite{ann:intro}.}
    \label{fig:neurona}
\end{figure}

Una neurona por sí sola no resulta de gran utilidad. Sin embargo, el potencial de las ANN comienza a ser notable cuando interconectamos varias neuronas entre sí, de tal manera que la salida de unas sea la entrada de otras y así sucesivamente, formando una red compleja.

La conexión entre las neuronas no se realiza de manera aleatoria, ya que sino los modelos generados serían inmanejables. Generalmente se siguen una serie de topologías que variarán en función del problema que se esté tratando \cite{ann:intro, cnn:ieee}. Las dos estructuras más básicas que podemos encontrar en una ANN son las descritas en la figura \ref{fig:red_neuronal}.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{img/red_neuronal.png}
    \caption{Izquierda: red neuronal de 3 capas y aprendizaje hacia adelante. Derecha: red neuronal de 3 capas y aprendizaje recurrente  \cite{ann:intro}.}
    \label{fig:red_neuronal}
\end{figure}

Una vez definida la estructura que compone la red, debemos llevar a cabo un entrenamiento, es decir, enseñar a la red a resolver el tipo de problema que deseemos. Podemos diferenciar 3 estrategias de aprendizaje de modelos: aprendizaje supervisado, aprendizaje no supervisado y aprendizaje por refuerzo.

La principal diferencia entre estos 3 paradigmas radica en el tipo de datos que se emplean para entrenar al modelo. En el caso del aprendizaje supervisado se usan datos etiquetados, es decir, para cada input se proporciona el correspondiente output; en el aprendizaje no supervisado se emplean datos no etiquetados, con el objetivo de que el modelo encuentre patrones o grupos ocultos presentes en esos datos al tratar de minimizar una función de coste específica; y finalmente el aprendizaje por refuerzo, en el que el modelo aprende mediante la interacción con el entorno y en base a la exploración y experiencia \cite{ann:intro, cnn:osea}.

El problema que nos ocupa se correspondería con un problema típico de aprendizaje supervisado, ya que poseemos una serie de inputs (las imágenes de fondo de ojo) y sus correspondientes etiquetas (el grado de retinopatía diabética del paciente al que corresponde esa imagen de fondo de ojo).

\subsubsection{Aprendizaje supervisado}

El aprendizaje supervisado, como se ha comentado anteriormente, es una estrategia de entrenamiento de ANN, para la cual se emplean conjuntos de datos etiquetados, es decir, para cada input que se introduce en el modelo se dispone de un output correspondiente, de manera que se comparan la salida predicha por el modelo y el output conocido. Esta idea es la base que permite al modelo ir aprendiendo y mejorando su rendimiento \cite{cnn:osea}. 

Para llevar a cabo el entrenamiento de un modelo, lo primero que debemos hacer es definir la topología que se desee entrenar, es decir, definir el número de neuronas que compondrán la red y cómo van a relacionarse entre sí (recordemos que la salida de unas será la entrada de otras) \cite{cnn:biblia_deeplearning}.

Tras la creación del modelo se deben inicializar los pesos de cada neurona de manera aleatoria, para evitar sesgos. El procedimiento más habitual es asignar un valor al azar a cada peso de cada neurona, tratando que los valores de los pesos sigan una distribución normal \cite{cnn:biblia_deeplearning}. Sin embargo, existen otras posibilidades a la hora de inicializar los pesos, como la inicialización de Glorot, inicialización de He o inicialización de LeCun, siendo esta última especialmente utilizada en CNNs \cite{cnn:inicializacion}.

Posteriormente tiene lugar lo que se denomina una propagación hacia delante (\textit{forward propagation}), es decir, se introduce un elemento (o varios en forma de lote) en la entrada de la red (con tantos valores input como sean requeridos) y a partir de esos valores input, mediante el cómputo entre las neuronas, la red calcula la salida. Como estamos trabajando con datos etiquetados, disponemos del valor de salida real correspondiente a la entrada introducida, por lo que el siguiente paso consiste en evaluar la discrepancia entre la predicción del modelo y el valor real \cite{cnn:biblia_deeplearning,cnn:biblia_machinelearning}.

Para poder calcular la diferencia entre ambos valores se emplea una \textbf{función de pérdida} (función \textit{loss}), que tiene como objetivo cuantificar qué tan bien realiza una predicción el modelo entrenado. Esta función \textit{loss} recibe como parámetros de entrada el valor real y la predicción, y devuelve un resultado que dependerá de la función empleada.  Algunas de las funciones \textit{loss} más comunes son la entropía cruzada (tanto binaria: \textit{Binary Cross-Entropy}, como categórica: \textit{Categorical Cross-Entropy}), pérdida cuadrática media (\textit{Mean Squared Error}) o función de log-verosimilitud (\textit{Log-Likelihood})\cite{cnn:biblia_deeplearning}.

Una vez calculado el valor de la función de pérdida, se inicia una propagación del mismo hacia atrás (\textit{backpropagation}), es decir, desde las neuronas finales hacia las más cercanas a la entrada del modelo. En este proceso de \textit{backpropagation} los distintos pesos de las neuronas modifican su valor, con el objetivo de tratar de mejorar futuras predicciones. La forma en que se modifiquen estos pesos, así como la \textit{cantidad} en que varíen, va a estar determinada por el \textbf{algoritmo de optimización}. Existen diversos algoritmos que se pueden emplear, siendo el principal el descenso de gradiente estocástico (SGD por sus siglas en inglés) y sus variantes y mejoras (Momentum, Adam, Adagrad...) \cite{cnn:biblia_deeplearning,cnn:biblia_machinelearning}.

Tras la actualización de los pesos de las neuronas el proceso se repite iterativamente, volviendo a introducir un elemento en la entrada del modelo y obteniendo una salida, calculando la función de pérdida y realizando nuevamente la \textit{backpropagation}... y así sucesivamente un número determinado de repeticiones o hasta que se considere que la precisión del modelo ha alcanzado su máximo \cite{cnn:biblia_deeplearning}.

\subsubsection{Concepto de convolución}

Una convolución es una operación matemática que combina y mezcla dos funciones, dando como resultado una tercera función. El símbolo empleado para representar esta operación es el asterisco ($\ast$) y la fórmula que representa la convolución entre la función $f$ y la función $g$ se puede encontrar en la ecuación \ref{eq:convolucion} \cite{cnn:biblia_deeplearning}.

\begin{equation}
    \centering
    \label{eq:convolucion}
    (f \ast g)(t)=\int f(\tau) g(t-\tau) d \tau
\end{equation}

Aunque la ecuación pueda parecer poco descriptiva, podemos entender una convolución, a grandes rasgos, como la operación en la cual se desplaza una función $g$ invertida sobre otra $f$, multiplicando aquellos valores superpuestos de ambas funciones y sumando los productos \cite{cnn:biblia_deeplearning}.

Esta operación se utiliza en distintos campos, como el procesamiento de señales, de vídeo o imágenes, ya que las funciones involucradas en la convolución pueden ser sustituidas por cualquier tipo de dato \cite{conv:matlab}.

Cuando hablamos de convolución en el contexto de procesamiento de imágenes, generalmente la imagen que deseamos procesar suele ocupar el lugar de la primera función $f$, mientras que la segunda función $g$ (aquella que se desplaza sobre la primera) se denomina \textit{kernel} o filtro \cite{cnn:biblia_deeplearning}.

Para ello es necesario comprender una imagen en blanco y negro como una matriz numérica, donde cada píxel de la imagen se corresponde con una celda de la matriz, y el valor de dicha celda dependerá del nivel de gris del píxel en la imagen (generalmente un valor entre $0$ y $2^n$, siendo $n$ el número de bits empleados en la codificación del píxel). Si se trata de una imagen a color (en codificación RGB), la representación será similar, pero tratándose en este caso de una matriz de 3 capas: una capa que alberga en cada celda el valor de la componente rojo de cada píxel, otra que alberga el valor de la componente azul y una tercera capa que almacena el valor de la componente verde de cada píxel \cite{cnn:images_process}.

Debido a que el \textit{kernel} que se desplaza sobre la imagen es también una matriz numérica de dimensiones $m*m$, siendo generalmente $m$ un número impar (típicamente $3, 5, 7$ o $9$), la operación de convolución en imágenes puede reducirse a un problema de convolución entre matrices. Tal y como se puede ver representado en la figura \ref{fig:convolucion}, para lograr la convolución entre una imagen de dimensiones $3$x$4$ y el filtro correspondiente de dimensiones $2$x$2$, se superponen ambas matrices de forma que se van multiplicando uno a uno el valor de las celdas superpuestas, para posteriormente sumar los resultados de los productos. Una vez realizado este proceso, el \textit{kernel} se desplaza un número de posiciones (en este caso una posición) y se repite el proceso. Como resultado de esta operación se obtiene una nueva matriz, de dimensiones  $2$x$3$, que puede interpretarse como una nueva imagen \cite{cnn:biblia_deeplearning}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{img/convolucion.png}
    \caption{Ejemplo de convolución 2-D entre 2 matrices. La matriz \textit{input} representa la imagen de entrada y la matriz \textit{kernel} el filtro \cite{cnn:biblia_deeplearning}.}
    \label{fig:convolucion}
\end{figure}

\subsubsection{Capas y funcionamiento}

Las CNNs con las que se ha trabajado están orientadas al reconocimiento de patrones en las imágenes, por lo que los datos de entrada se espera que sean imágenes. Es por ello que la arquitectura de estos modelos está específicamente diseñada para ser lo más eficiente posible en el manejo de este tipo de datos de entrada \cite{cnn:osea}. 

En el contexto de las CNN, cada una de las operaciones que se realizan sobre los valores de entrada se denomina \lq\lq capa\rq\rq. Es decir, una capa puede entenderse como una unidad de procesamiento, un componente de la red, encargado de realizar una determinada operación (como por ejemplo la convolución). Podemos encontrar distintos tipos de capas dentro de una CNN \cite{cnn:gu}. A continuación se hace referencia a algunas de las más habituales.

\textbf{Capa convolucional}. Como puede intuirse por su nombre, este tipo de capa desempeña un papel fundamental en el flujo de trabajo de una CNN. Cuando la matriz que representa la imagen llega a una capa convolucional, esta realiza la operación de convolución entre la imagen recibida y tantos filtros como se desee. Por tanto, si una capa convolucional de $n$ filtros recibe una única matriz como entrada, tras la salida de esta capa se obtendrán $n$ matrices. Dependiendo de las características de la capa convolucional, puede que las dimensiones de la imagen de salida disminuyan conforme a las dimensiones originales \cite{cnn:osea, cnn:gu}. 

El objetivo de este tipo de capas es extraer las características relevantes de la imagen obtenida como entrada. Para ello cada uno de los filtros de la capa se especializa en el reconocimiento de un tipo concreto de características. Esta labor de especialización se realiza de manera automática, conforme la red se entrena con más ejemplos, las funciones de pérdida y de optimización van provocando el cambio en los pesos de los filtros, logrando así mejorar el rendimiento \cite{cnn:biblia_deeplearning, cnn:osea}. En la figura \ref{fig:filtros} se puede observar el efecto que tienen distintos filtros sobre una imagen.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{img/filtros.png}
    \caption{Efecto de distintos filtros de convolución sobre una imagen \cite{cnn:ieee}.}
    \label{fig:filtros}
\end{figure}

Existen varios hiperparámetros que determinan el funcionamiento de una capa convolucional. Entre ellos se encuentran el número de filtros que aplica la capa sobre la matriz de entrada, también denominado profundidad, que determina a su vez el número de matrices de salida; el tamaño del \textit{kernel} (generalmente se trata de un número impar); el tamaño de paso (\textit{stride}), que se refiere al número de píxeles que se desplaza el \textit{kernel} sobre la matriz en el momento de realizar la convolución, y el relleno (\textit{padding}), que hace referencia al número de píxeles de relleno, con valor $0$, que se añaden como marco de la imagen y que permite preservar las dimensiones de la imagen de entrada en la salida \cite{cnn:osea, cnn:ieee}.

\textbf{Capa de \textit{pooling}}. Esta capa tiene como objetivo reducir las dimensiones de la matriz que recibe como entrada. Consta de un filtro, de dimensiones $n$x$n$, que va desplazándose sobre la matriz recibida como entrada y devuelve un único valor. Por tanto, una capa de \textit{pooling} con un filtro de dimensiones $n$x$n$ producirá una transformación $n:1$ \cite{cnn:cheatsheet, cnn:osea}.

Podemos diferenciar entre diversos tipos de capas de \textit{pooling}, según la estrategia que sigan para seleccionar el valor que devuelve el filtro, pero la más común es \textit{Max pooling}, que devuelve el valor más alto de entre todos aquellos cubiertos por el filtro \cite{cnn:ieee, cnn:cheatsheet}.

Entre los hiperparámetros que pueden modificarse en este tipo de capas se encuentran el tamaño de paso (\textit{stride}) y el tamaño del filtro (en este caso suelen ser valores pares). Generalmente esta capa suele aplicarse tras una capa convolucional, para reducir el número de conexiones entre capas convolucionales y disminuir así la complejidad de la red \cite{cnn:gu}.

\textbf{Capa de activación}. La función de esta capa es modificar los datos de salida tras una capa convolucional para introducir una no linealidad en el modelo. Consiste en una función no lineal que se aplica individualmente a cada valor de la salida, con el objetivo de que estos valores sean no lineales \cite{cnn:ieee, cnn:gu}.

Con esta modificación de los datos se busca mejorar el rendimiento del modelo, ya que al introducir no linealidades permiten que la red aprenda relaciones más complejas, así como características más discriminativas de los datos y se da solución al problema del desvanecimiento del gradiente (la disminución del gradiente del optimizador conforme se acerca a las capas anteriores), lo que permite entrenar redes más profundas \cite{cnn:activacion, cnn:biblia_deeplearning}.

La función que desempeñe esta activación de los datos puede variar según el modelo desarrollado. Algunas de las más comunes son ReLU (\textit{Rectified Linear Unit}, que consiste básicamente en sustituir los valores negativos por cero y mantener los valores positivos inalterados; PReLU (Parametric Rectified Linear Unit), que modifica ligeramente la función ReLU ya que los valores negativos no los sustituye por cero, sino que los multiplica por un valor determinado que va variando conforme aprende la red; y Maxout, que no consiste en una única función, sino en una familia de funciones capaces de aprender representaciones no lineales, donde se selecciona aquella función que proporciona el valor máximo \cite{cnn:gu, cnn:cheatsheet}.

\textbf{Capa de regularización}. Para tratar de evitar el sobreentrenamiento de los modelos, es decir, que la red se especialice demasiado en el conjunto de datos de entrenamiento y pierda capacidad de generalización, se suele incluir este tipo de capas en algunas arquitecturas \cite{cnn:gu}. La estrategia seguida por la mayoría de estas capas consiste en restringir el modelo durante el aprendizaje, reduciendo la complejidad de este y tratando de encontrar el equilibrio entre los datos de entrenamiento y la capacidad de generalización del modelo \cite{cnn:biblia_deeplearning}.

La dos estrategias de regularización más habituales son L1 y L2, que penalizan los pesos altos, provocando que el modelo desista de asignar valores excesivamente grandes a los pesos, y \textit{Dropout}, que consiste en apagar aleatoriamente un porcentaje de neuronas del modelo tras cada propagación hacia adelante, provocando así que las neuronas restantes se vean obligadas a robustecerse y mejorar su capacidad de generalización \cite{cnn:biblia_deeplearning}.

\textbf{Capa densa o \textit{fully-connected}}. Generalmente forma parte de las últimas capas del modelo, y suelen aparecer varias de ellas consecutivas (y conectadas entre sí). Constituyen una red neuronal artificial, con $n$ neuronas de entrada (que constituyen la primera capa \textit{fully-connected} y $m$ neuronas de salida. El número de neuronas de entrada ($n$) dependerá de las capas anteriores del modelo, así como las dimensiones iniciales de la imagen. El número de neuronas de salida ($m$) será típicamente $1$ si se trata de un problema de clasificación binaria (las etiquetas son dicotómicas), y será igual al número de posibles clases en un problema de clasificación multiclase \cite{cnn:ieee, cnn:osea}.

Una vez definidas las distintas capas podemos encontrar en una CNN voy a explicar el \textbf{flujo de trabajo} que suele producirse y cómo las capas se relacionan entre sí.

Una CNN recibe generalmente varias imágenes en forma de lote o \textit{batch}, pero para mayor sencillez a la hora de explicar el funcionamiento consideraremos únicamente una imagen. Habitualmente la primera capa del modelo es una capa convolucional, con los hiperparámetros que correspondan. Esta capa recibe como input la imagen, realiza la convolución con cada uno de los filtros que correspondan y devolverá en la salida tantas matrices como se hayan generado al convolucionar. Tras la capa convolucional se encuentra la capa de activación, que modificará los valores de cada matriz para introducir no linealidades, por lo que la salida de esta capa sigue siendo el mismo número de matrices y con las mismas dimensiones que en la entrada. Posteriormente suele encontrarse la capa de \textit{pooling}, que reduce las dimensiones de cada matriz, pero el número total de matrices no se ve alterado \cite{cnn:biblia_deeplearning, cnn:gu}.

Este conjunto de capas (convolucional, activación, \textit{pooling}) puede repetirse consecutivamente varias veces, variando el valor de los hiperparámetros de estas capas. Tras múltiples capas de convolución, activación y \textit{pooling} obtenemos un número de matrices determinado (correspondiente con el número de filtros de la última capa) de unas dimensiones concretas. Entre conjunto de capas convolucionales se pueden introducir capas de regularización, que no afectan a los valores de los datos, pero influyen en la forma de aprender del modelo, para evitar el sobreentrenamiento \cite{cnn:biblia_machinelearning}.

Para poder introducir esta información en las capas densas debe realizarse un proceso denominado aplanamiento o \textit{flattening}, por el cual todos los valores ubicados en las matrices generadas en la última capa deben \lq\lq aplanarse\rq\rq, es decir, los elementos de todas las celdas deben disponerse en una fila o vector unidimensional. Si en la última capa se generaron $m$ matrices de $n$x$n$ dimensiones, al realizar este aplanamiento obtendremos una lista de $m$x$n$x$n$ elementos. Es esta lista la que se introduce como input en la primera capa densa, que deberá tener por tanto $m$x$n$x$n$ neuronas \cite{cnn:biblia_deeplearning, cnn:osea}.

Las distintas capas densas también pueden ir intercaladas por capas de activación, para introducir no linealidades. Tras la ejecución de todas las capas densas se encuentra la última capa de neuronas que es la que proporciona la salida. Como se ha mencionado anteriormente el número de neuronas de esta capa dependerá del número de etiquetas distintas que tenga nuestro problema \cite{cnn:ieee, cnn:biblia_deeplearning}. 

\titlespacing{\section}{0pt}{0.25cm}{0.15cm}
\section{Estado del arte y trabajos relacionados}

Para la búsqueda de trabajos relacionados se usaron los siguientes términos de búsqueda: \textit{CNN, diabetic retinopathy, smartphone}. En aquellos repositorios en que no aparecía ningún resultado se probó a sustituir el último término por \textit{mobile}.

Se ha llevado a cabo una revisión de la literatura en Web Of Science, Google Scholar, Science Direct, Scopus y PubMed de un total de 74 artículos (3 de ellos correspondientes a Web of Science, 64 a Google Scholar, 1 a Science Direct, 5 a Scopus y 1 a PubMed). Para realizar la búsqueda no se tuvieron en cuenta las revisiones bibliográficas (\textit{review}), y en Google Scholar se consideraron únicamente aquellas publicaciones realizadas en el año 2022 y se sustituyó el último término por los términos \textit{iPhone, Android}\footnote{Se decidió realizar este filtrado ya que si no el número de resultados superaba las 5000 publicaciones}.

De los 74 artículos encontrados, solo 4 fueron considerados para su estudio. Los otros 70 restantes fueron excluidos por alguno de los siguientes motivos:

\begin{itemize} [itemsep=0.25em]
    \item No emplear imágenes tomadas con teléfono móvil en el entrenamiento/evaluación de los modelos (12 artículos).
    \item Estar enfocados en el entrenamiento de CNNs con otra finalidad diferente al diagnóstico de RD (41 artículos).
    \item Estar repetidos en distintos repositorios (3 artículos).
    \item Tratarse de revisiones bibliográficas no filtradas previamente (14 artículos).
\end{itemize}

\newpage
\textit{Artículos seleccionados entre 2020 y 2023}

[Simon Mueller. 2020] Este estudio se enfoca en el uso de un dispositivo (Paxos Scope) para la adquisición de vídeo de la retina de los pacientes, acoplando este dispositivo a la cámara de un teléfono móvil. Se plantea un flujo de trabajo en 3 pasos para el análisis de las imágenes. Primero se recorta cada uno de los fotogramas del vídeo para seleccionar únicamente la subregión de cada fotograma en la que aparece la imagen de la retina. Posteriormente se seleccionan aquellos fotogramas que proporcionan mayor información empleando para ello estrategias de inteligencia artificial como \textit{Support Vector Machine}, con el objetivo de seleccionar aquellos fotogramas en los que la imagen de retina fuera lo más nítida posible. Por último se lleva a cabo la clasificación de las imágenes en los distintos grados de RD utilizando aprendizaje de múltiples instancias (MIL por sus siglas en inglés) junto con un mecanismo de atención que permite a la CNN empleada aprender en qué fotogramas debe basar la predicción \cite{soa:mueller}. 

Se probaron distintas CNNs siguiendo una estrategia de \textit{Transfer Learning}, usando modelos ya entrenados con grandes conjuntos de imágenes y posteriormente especializándolos en este problema en particular (lo que se denomina ajuste fino). Emplearon el modelo preentrenado 'AlexNet', empleando 83126 imágenes para su especialización, obteniendo una precisión de 0.750, una tasa de detección (\textit{recall}) de 0.667, un F-score de 0.706 y un valor AUC de 0.841 \cite{soa:mueller}.

Para el desarrollo del proyecto se empleó Python como lenguaje de programación, usando las bibliotecas de OpenCV, Pandas, scikit-learn y PyTorch \cite{soa:mueller}.

[Mohamed Akil. 2021] Este artículo realiza una descripción breve de los distintos dispositivos que se han desarrollado para la adquisición de imágenes de fondo de ojo empleando la cámara de teléfonos móviles, como D-EYE, PEEK Retina o HFC MicroClear. Tras esta breve presentación de las distintas opciones de \textit{hardware} disponibles, se mencionan los modelos desarrollados para el análisis de las imágenes obtenidas con estos dispositivos \cite{soa:mohamed}. 

El primero de los modelos descritos recibe el nombre de 'EyeArt', diseñado para detectar RD y diferenciar entre NPDR no severa y NPDR severa o PDR. Para el entrenamiento de la red se usaron imágenes de fondo de ojo de 78685 pacientes, alcanzando una sensibilidad del 95.8\% y una especificidad del 80.2\% \cite{soa:mohamed}.

La segunda arquitectura descrita fue diseñada para la clasificación de imágenes de fondo de ojo obtenidas con el dispositivo D-EYE. Sigue la estrategia de \textit{Transfer Learning}, utilizando el modelo preentrenado 'Xception'. Para el ajuste fino del modelo se emplearon 23354 imágenes, obteniendo un porcentaje de exactitud del 94.6\% \cite{soa:mohamed}.

[Seetha Maddala. 2022] En esta publicación nuevamente se emplea el dispositivo D-EYE para la adquisición de vídeo de fondo de ojo utilizando la cámara de un teléfono móvil. En la toma de imágenes se emplearon únicamente teléfonos con sistema operativo iOS, debido a los requerimientos de compatibilidad con la aplicación de D-EYE. Tras la obtención de vídeos utilizando esta herramienta, se escogieron manualmente los mejores fotogramas y posteriormente se procesaron para eliminar el ruido y ajustar la imagen al círculo del fondo de ojo. Para mejorar la calidad de estas imágenes se empleó el modelo neuronal SRGAN \cite{soa:seetha}. 

Para lograr la clasificación de las imágenes se empleó una arquitectura de CNN propia formada por 3 capas convolucionales y sus 3 capas correspondientes de \textit{pooling}, posteriormente una capa de regularización (\textit{Dropout}) y finalmente una capa densa. Se utilizaron 200 imágenes para el entrenamiento del modelo, y 100 más para la puesta a prueba, consiguiendo una precisión de 0.89, \textit{recall} de 0.88 y un valor de F-score de 0.8849.

[Mohammad Alatoum. 2023] En este estudio, al igual que en los mencionados anteriormente, se desarrolló un modelo de CNN para la detección de RD empleando imágenes tomadas con dispositivos móviles. En este caso, el objetivo no era lograr un diagnóstico capaz de identificar el grado de RD, sino detectar la presencia/ausencia de enfermedad, tratándose de un problema de clasificación binaria. El dispositivo empleado para la obtención de las fotografías de fondo de ojo en esta ocasión fue el denominado '20D', y el teléfono móvil usado fue el modelo Z-10 de la marca Blackberry \cite{soa:mohammad}.

La CNN empleada fue construida desde cero empleando la biblioteca Keras, del marco de trabajo TensorFlow. El modelo consta de 3 capas convolucionales, cada una de ellas de 32 filtros, y sus correspondientes 3 capas de \textit{pooling}. Tras estas 6 capas se encuentra una capa densa y finalmente la capa de salida. Para el entrenamiento del modelo se emplearon 1200 imágenes de fondo de ojo, adquiridas del repositorio público del programa Messidor. Cada una de las imágenes fueron posteriormente preprocesadas, eliminando el fondo de las fotografías, redimensionándolas (256x256 píxels) y convirtiéndolas a escala de gris. Por último, aquellas imágenes etiquetadas como casos positivos, se rotaron 90, 120, 180 y 270 grados, con el objetivo de obtener una mayor cantidad de imágenes con RD y así solucionar el desbalanceo entre clases. El porcentaje de acierto del modelo, usando las imágenes obtenidas con el dispositivo '20D' fue del 81.6\% \cite{soa:mohammad}.

Además del diseño y entrenamiento del modelo, en la publicación también se hace referencia al desarrollo de una aplicación móvil, tanto para Android como para iOS, que permita obtener una predicción por parte del modelo a partir de una imagen tomada en el mismo dispositivo en que se encuentra la aplicación instalada \cite{soa:mohammad}.