{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00186483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#primero importamos todos los paquetes necesarios\n",
    "import torch #contiene todas las funciones de PyTorch\n",
    "import torch.nn as nn #contiene la clase padre de todos los modelos (nn.Module)\n",
    "import torch.nn.functional as F #esencial para la función de activación \n",
    "import torchvision #fundamental para la importación de imágenes\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt #para poder representar las gráficas\n",
    "import numpy as np #para las métricas de la red\n",
    "\n",
    "#importamos también las funcioness definidas para el entrenamiento y puesta a prueba de los modelos\n",
    "from modules.CNN_utilities import entrena, representa_test, representa_train, tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e58814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de datos de train: 113\n",
      "Tamaño del conjunto de datos de test de Samsung: 93\n",
      "Tamaño del conjunto de datos de test de iPhone: 99\n"
     ]
    }
   ],
   "source": [
    "#establecemos el tamaño del batch, la escala de las imágenes y el número de épocas de entrenamiento\n",
    "batch = 4\n",
    "#la arquitectura propuesta por Ghosh requiere una escala de 512, 512, 3\n",
    "escala = 512\n",
    "epocas = 50\n",
    "\n",
    "#a continuación definimos la operación que permitirá transformar las imágenes del repositorio en Tensores que puedan ser empleados por PyTorch\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), #transforma la imagen de formato PIL a formato tensor\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), #normaliza el tensor para que la media de sus valores sea 0 y su desviación estándar 0.5\n",
    "     transforms.Resize((escala, escala))]) #redimensionamos las imágenes\n",
    "\n",
    "#a continuación cargamos el conjunto de imágenes de train (OCT) y los dos de test (iPhone y Samsung)\n",
    "OCT = ImageFolder(root = 'Datos/Classified Data/Images/OCT', transform = transform)\n",
    "print(f'Tamaño del conjunto de datos de train: {len(OCT)}')\n",
    "\n",
    "Samsung = ImageFolder(root = 'Datos/Classified Data/Images/Samsung', transform = transform)\n",
    "print(f'Tamaño del conjunto de datos de test de Samsung: {len(Samsung)}')\n",
    "\n",
    "iPhone = ImageFolder(root = 'Datos/Classified Data/Images/iPhone', transform = transform)\n",
    "print(f'Tamaño del conjunto de datos de test de iPhone: {len(iPhone)}')\n",
    "\n",
    "#establecemos una lista con el nombre de las etiquetas\n",
    "classes = OCT.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd9fde96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y definimos también las funciones que van a ir cargando las imágenes en el modelo\n",
    "train_loader = DataLoader(\n",
    "    dataset = OCT,\n",
    "    batch_size = 4, #establecemos un tamaño de lote (batch_size) de 4, ya que son pocas imágenes y podemos permitírnoslo\n",
    "    shuffle = True, #indicamos que mezcle las imágenes\n",
    "    num_workers = 2 #genera subprocesos para cargar los datos y así liberamos el proceso main\n",
    ")\n",
    "\n",
    "test_S_loader = DataLoader(\n",
    "    dataset = Samsung,\n",
    "    batch_size = 4, #establecemos un tamaño de lote (batch_size) de 10, ya que son pocas imágenes y podemos permitírnoslo\n",
    "    shuffle = True, #indicamos que mezcle las imágenes\n",
    "    num_workers = 2 #genera subprocesos para cargar los datos y así liberamos el proceso main\n",
    ")\n",
    "\n",
    "test_i_loader = DataLoader(\n",
    "    dataset = iPhone,\n",
    "    batch_size = 4, #establecemos un tamaño de lote (batch_size) de 10, ya que son pocas imágenes y podemos permitírnoslo\n",
    "    shuffle = True, #indicamos que mezcle las imágenes\n",
    "    num_workers = 2 #genera subprocesos para cargar los datos y así liberamos el proceso main\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a29af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A lo largo de este script voy a probar a variar algunos parámetros del modelo (intentando no perder la esencia de la estructura original)\n",
    "#Los parámetros modificados serán los siguientes:\n",
    "# - reducción del número de capas convolucionales (incluir únicamente las 6 primeras capas para disminuir la complejidad)\n",
    "# - empleando una serie decreciente de neuronas en las capas fully-connected probar las siguientes combinaciones:\n",
    "#       * 1024, 512, 256\n",
    "#       * 512, 256, 128\n",
    "#       * 256, 128, 64\n",
    "# nuevamente con el objetivo de reducir la complejidad de la red y tratar de mejorar los resultados.\n",
    "#Existen por tanto 6 posibles variantes (combinando ambos parámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c3e591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#Primera variante: 13 capas convolucionales y neuronas FC (fully-connected) 1024, 512, 256\n",
    "class Primera_var(nn.Module):\n",
    "    #esta estructura está formada por capas convolucionales, de maxpooling, de activación, de Dropout, fully-connected y de clasificación\n",
    "    \n",
    "    def __init__(self):\n",
    "        #sobreescribimos el constructor del padre\n",
    "        super(Primera_var,self).__init__()\n",
    "        #primero definimos una capa convolucional\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = 3, #3 canales de entrada porque las imágenes son a color\n",
    "            out_channels = 32, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 7, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la segunda (y tercera) capa convolucional, se pueden definir como una única porque el número de entradas y salidas coincide\n",
    "        self.conv2_3 = nn.Conv2d(\n",
    "            in_channels = 32, #32 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 32, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la cuarta capa convolucional\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels = 32, #32 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 64, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la quinta capa convolucional\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels = 64, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 64, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la sexta capa convolucional\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels = 64, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 128, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la séptima (y octava y novena) capa convolucional\n",
    "        self.conv7_8_9 = nn.Conv2d(\n",
    "            in_channels = 128, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 128, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la décima capa convolucional\n",
    "        self.conv10 = nn.Conv2d(\n",
    "            in_channels = 128, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 256, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #las últimas 3 capa convolucionales\n",
    "        self.conv11_12_13 = nn.Conv2d(\n",
    "            in_channels = 256, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 256, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la función de activación (en este caso PReLU)\n",
    "        self.activation = nn.PReLU()\n",
    "        \n",
    "        #la capa de MaxPool\n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = 2, #establecemos el tamaño del kernel a 2*2\n",
    "            stride = 2 #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "        )\n",
    "        \n",
    "        #la primera capa de neuronas a la que aplicaremos Dropout como técnica de regularización\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features = 256, #número de características de entrada\n",
    "            out_features = 1024 #número de neuronas de salida\n",
    "        )\n",
    "        \n",
    "        #la segunda capa fully-connected\n",
    "        self.fc2 = nn.Linear(1024,512)\n",
    "        \n",
    "        #la tercera capa fully-connected\n",
    "        self.fc3 = nn.Linear(512,256)\n",
    "        \n",
    "        #la capa de neuronas fully-connected final\n",
    "        self.dense = nn.Linear(\n",
    "            in_features = 256, #número de parámetros de entrada de la red (los valores se obtienen experimentalmente)\n",
    "            out_features = 5 #número de neuronas de salida\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #en esta función es donde tiene lugar la computación (y la función invocada por defecto al ejecutar la red)\n",
    "        #siguiendo la estructura descrita en Ghosh et al.:\n",
    "        \n",
    "        #primero una capa convolucional de tipo 1, con su consecuente activación PReLU y la capa de MaxPool\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        #una capa convolucional de tipo 2 con su correspondiente activación\n",
    "        x = self.activation(self.conv2_3(x))\n",
    "        #capa convolucional de tipo 2 con activación y MaxPool\n",
    "        x = self.pool(self.activation(self.conv2_3(x)))\n",
    "        #cuarta convolucional con activación\n",
    "        x = self.activation(self.conv4(x))\n",
    "        #quinta convolucional con activación y MaxPool\n",
    "        x = self.pool(self.activation(self.conv5(x)))\n",
    "        #3 capas convolucionales consecutivas de tipo 2 con su correspondiente activación\n",
    "        x = self.activation(self.conv6(x))\n",
    "        x = self.activation(self.conv7_8_9(x))\n",
    "        x = self.activation(self.conv7_8_9(x))\n",
    "        #novena capa convolucional con activación y MaxPool\n",
    "        x = self.pool(self.activation(self.conv7_8_9(x)))\n",
    "        #se repite la misma estructura de 3 capas convolucionales con activación y una última con activación y MaxPool\n",
    "        x = self.activation(self.conv10(x))\n",
    "        x = self.activation(self.conv11_12_13(x))\n",
    "        x = self.activation(self.conv11_12_13(x))\n",
    "        x = self.pool(self.activation(self.conv11_12_13(x)))\n",
    "        #aplanamos la salida, hasta convertirla de forma matricial a forma vectorial (sería la capa flatten)\n",
    "        x = x.view(-1,self.num_flat_features(x))#usamos una función propia de la clase para obtener el número de características\n",
    "        #aplicamos una primera red neuronal fully-connected, con la activación consecuente y la estrategia dropout para evitar el sobreentrenamiento\n",
    "        x = F.dropout(self.activation(self.fc1(x)))\n",
    "        #lo mismo sucede con la segunda capa fully-connected\n",
    "        x = F.dropout(self.activation(self.fc2(x)))\n",
    "        #y con la tercera\n",
    "        x = F.dropout(self.activation(self.fc3(x)))\n",
    "        #por último tiene lugar la capa de predicciones, que convierte las 512 neuronas de la tercera capa fully-connected en una salida de 5 neuronas (una por clase)\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        #por último definimos la función que permite obtener el número de características de los tensores\n",
    "        size = x.size()[1:] #seleccionamos todas las dimensiones expcepto la primera (que son los batches)\n",
    "        num_features = 1\n",
    "        #va iterando y calcula el número de características de los datos (x)\n",
    "        for s in size:\n",
    "            num_features*=s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1177f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primera_var(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))\n",
      "  (conv2_3): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv7_8_9): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv11_12_13): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (activation): PReLU(num_parameters=1)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (dense): Linear(in_features=256, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#creamos una instancia de esta red\n",
    "primera = Primera_var()\n",
    "#mostramos su estructura\n",
    "print(primera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a53d22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos como loss la función de tipo cross entropy \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "#en este caso el optimizador será la función Adam (ampliamente utilizada)\n",
    "optimizer = torch.optim.Adam(params = primera.parameters()) #dejamos el valor de learning-rate por defecto (0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b1dfdd8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/50 - Accuracy: 0.4690265486725664 - Loss: 0.8141241669654846\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#entrenamos la red haciendo uso de la función 'entrena()' importada\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mentrena\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimera\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepocas\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\UBU\\4º curso\\TFG\\CNN_and_Diabetic_Retinopathy\\modules\\CNN_utilities.py:45\u001b[0m, in \u001b[0;36mentrena\u001b[1;34m(red, epocas, train_loader, optimizer, criterion)\u001b[0m\n\u001b[0;32m     43\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#y cargamos las imágenes de entrenamiento y sus etiquetas usando la estructura Loader pasada como parámetro\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m#obtenemos las imágenes y etiquetas del lote por separado\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m#establecemos a 0 los parámetros del modelo\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1282\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1284\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1120\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1123\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:335\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    333\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:884\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    882\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 884\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:816\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    814\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 816\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#entrenamos la red haciendo uso de la función 'entrena()' importada\n",
    "#recogemos los resultados en 2 variables que posteriormente nos permitirán representar la evolución de accuracy y loss\n",
    "acc,loss = entrena(primera,epocas,train_loader,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#representamos la evolución temporal de accuracy\n",
    "representa_train(acc,'Accuracy','Ghosh - Primera Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef54376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y representamos el loss\n",
    "representa_train(acc,'Loss','Ghosh - Primera Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalmente ponemos a prueba la red usando la función tester y recogemos los resultados para obtener las métricas\n",
    "y_true_iphone, y_pred_iphone, predictions_iphone = tester(primera,test_i_loader)\n",
    "#y posteriormente obtenemos y mostramos las métricas\n",
    "representa_test(y_true_iphone,y_pred_iphone,predictions_iphone,'iPhone','Primera Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f084a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repetimos el mismo proceso pero empleando el conjunto de imágenes de Samsung\n",
    "y_true_samsung, y_pred_samsung, predictions_samsung = tester(primera,test_S_loader)\n",
    "#y posteriormente obtenemos y mostramos las métricas\n",
    "representa_test(y_true_samsung,y_pred_samsung,predictions_samsung,'Samsung','Primera Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e29ce414",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#Segunda variante: 13 capas convolucionales y neuronas FC (fully-connected) 512, 256, 128\n",
    "class Segunda_var(nn.Module):\n",
    "    #esta estructura está formada por capas convolucionales, de maxpooling, de activación, de Dropout, fully-connected y de clasificación\n",
    "    \n",
    "    def __init__(self):\n",
    "        #sobreescribimos el constructor del padre\n",
    "        super(Segunda_var,self).__init__()\n",
    "        #primero definimos una capa convolucional\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = 3, #3 canales de entrada porque las imágenes son a color\n",
    "            out_channels = 32, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 7, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la segunda (y tercera) capa convolucional, se pueden definir como una única porque el número de entradas y salidas coincide\n",
    "        self.conv2_3 = nn.Conv2d(\n",
    "            in_channels = 32, #32 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 32, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la cuarta capa convolucional\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels = 32, #32 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 64, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la quinta capa convolucional\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels = 64, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 64, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la sexta capa convolucional\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels = 64, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 128, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la séptima (y octava y novena) capa convolucional\n",
    "        self.conv7_8_9 = nn.Conv2d(\n",
    "            in_channels = 128, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 128, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la décima capa convolucional\n",
    "        self.conv10 = nn.Conv2d(\n",
    "            in_channels = 128, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 256, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #las últimas 3 capa convolucionales\n",
    "        self.conv11_12_13 = nn.Conv2d(\n",
    "            in_channels = 256, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 256, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la función de activación (en este caso PReLU)\n",
    "        self.activation = nn.PReLU()\n",
    "        \n",
    "        #la capa de MaxPool\n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = 2, #establecemos el tamaño del kernel a 2*2\n",
    "            stride = 2 #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "        )\n",
    "        \n",
    "        #la primera capa de neuronas a la que aplicaremos Dropout como técnica de regularización\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features = 256, #número de características de entrada\n",
    "            out_features = 512 #número de neuronas de salida\n",
    "        )\n",
    "        \n",
    "        #la segunda capa fully-connected\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        \n",
    "        #la tercera capa fully-connected\n",
    "        self.fc3 = nn.Linear(256,128)\n",
    "        \n",
    "        #la capa de neuronas fully-connected final\n",
    "        self.dense = nn.Linear(\n",
    "            in_features = 128, #número de parámetros de entrada de la red (los valores se obtienen experimentalmente)\n",
    "            out_features = 5 #número de neuronas de salida\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #en esta función es donde tiene lugar la computación (y la función invocada por defecto al ejecutar la red)\n",
    "        #siguiendo la estructura descrita en Ghosh et al.:\n",
    "        \n",
    "        #primero una capa convolucional de tipo 1, con su consecuente activación PReLU y la capa de MaxPool\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        #una capa convolucional de tipo 2 con su correspondiente activación\n",
    "        x = self.activation(self.conv2_3(x))\n",
    "        #capa convolucional de tipo 2 con activación y MaxPool\n",
    "        x = self.pool(self.activation(self.conv2_3(x)))\n",
    "        #cuarta convolucional con activación\n",
    "        x = self.activation(self.conv4(x))\n",
    "        #quinta convolucional con activación y MaxPool\n",
    "        x = self.pool(self.activation(self.conv5(x)))\n",
    "        #3 capas convolucionales consecutivas de tipo 2 con su correspondiente activación\n",
    "        x = self.activation(self.conv6(x))\n",
    "        x = self.activation(self.conv7_8_9(x))\n",
    "        x = self.activation(self.conv7_8_9(x))\n",
    "        #novena capa convolucional con activación y MaxPool\n",
    "        x = self.pool(self.activation(self.conv7_8_9(x)))\n",
    "        #se repite la misma estructura de 3 capas convolucionales con activación y una última con activación y MaxPool\n",
    "        x = self.activation(self.conv10(x))\n",
    "        x = self.activation(self.conv11_12_13(x))\n",
    "        x = self.activation(self.conv11_12_13(x))\n",
    "        x = self.pool(self.activation(self.conv11_12_13(x)))\n",
    "        #aplanamos la salida, hasta convertirla de forma matricial a forma vectorial (sería la capa flatten)\n",
    "        x = x.view(-1,self.num_flat_features(x))#usamos una función propia de la clase para obtener el número de características\n",
    "        #aplicamos una primera red neuronal fully-connected, con la activación consecuente y la estrategia dropout para evitar el sobreentrenamiento\n",
    "        x = F.dropout(self.activation(self.fc1(x)))\n",
    "        #lo mismo sucede con la segunda capa fully-connected\n",
    "        x = F.dropout(self.activation(self.fc2(x)))\n",
    "        #y con la tercera\n",
    "        x = F.dropout(self.activation(self.fc3(x)))\n",
    "        #por último tiene lugar la capa de predicciones, que convierte las 512 neuronas de la tercera capa fully-connected en una salida de 5 neuronas (una por clase)\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        #por último definimos la función que permite obtener el número de características de los tensores\n",
    "        size = x.size()[1:] #seleccionamos todas las dimensiones expcepto la primera (que son los batches)\n",
    "        num_features = 1\n",
    "        #va iterando y calcula el número de características de los datos (x)\n",
    "        for s in size:\n",
    "            num_features*=s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3583c7f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segunda_var(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))\n",
      "  (conv2_3): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv7_8_9): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv11_12_13): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (activation): PReLU(num_parameters=1)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (dense): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#creamos una instancia de esta red\n",
    "segunda = Segunda_var()\n",
    "#mostramos su estructura\n",
    "print(segunda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd48a05c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/50 - Accuracy: 0.4690265486725664 - Loss: 0.8141241669654846\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#entrenamos la red haciendo uso de la función 'entrena()' importada\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mentrena\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimera\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepocas\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\UBU\\4º curso\\TFG\\CNN_and_Diabetic_Retinopathy\\modules\\CNN_utilities.py:45\u001b[0m, in \u001b[0;36mentrena\u001b[1;34m(red, epocas, train_loader, optimizer, criterion)\u001b[0m\n\u001b[0;32m     43\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#y cargamos las imágenes de entrenamiento y sus etiquetas usando la estructura Loader pasada como parámetro\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m#obtenemos las imágenes y etiquetas del lote por separado\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m#establecemos a 0 los parámetros del modelo\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1282\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1284\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1120\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1123\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:335\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    333\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:884\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    882\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 884\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:816\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    814\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 816\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#entrenamos la red haciendo uso de la función 'entrena()' importada\n",
    "#recogemos los resultados en 2 variables que posteriormente nos permitirán representar la evolución de accuracy y loss\n",
    "acc,loss = entrena(segunda,epocas,train_loader,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f97537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#representamos la evolución temporal de accuracy\n",
    "representa_train(acc,'Accuracy','Ghosh - Segunda Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e073a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y representamos el loss\n",
    "representa_train(acc,'Loss','Ghosh - Segunda Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalmente ponemos a prueba la red usando la función tester y recogemos los resultados para obtener las métricas\n",
    "y_true_iphone, y_pred_iphone, predictions_iphone = tester(segunda,test_i_loader)\n",
    "#y posteriormente obtenemos y mostramos las métricas\n",
    "representa_test(y_true_iphone,y_pred_iphone,predictions_iphone,'iPhone','Segunda Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd2325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repetimos el mismo proceso pero empleando el conjunto de imágenes de Samsung\n",
    "y_true_samsung, y_pred_samsung, predictions_samsung = tester(segunda,test_S_loader)\n",
    "#y posteriormente obtenemos y mostramos las métricas\n",
    "representa_test(y_true_samsung,y_pred_samsung,predictions_samsung,'Samsung','Segunda Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01040bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#Tercera variante: 13 capas convolucionales y neuronas FC (fully-connected) 256, 128, 64\n",
    "class Tercera_var(nn.Module):\n",
    "    #esta estructura está formada por capas convolucionales, de maxpooling, de activación, de Dropout, fully-connected y de clasificación\n",
    "    \n",
    "    def __init__(self):\n",
    "        #sobreescribimos el constructor del padre\n",
    "        super(Tercera_var,self).__init__()\n",
    "        #primero definimos una capa convolucional\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = 3, #3 canales de entrada porque las imágenes son a color\n",
    "            out_channels = 32, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 7, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la segunda (y tercera) capa convolucional, se pueden definir como una única porque el número de entradas y salidas coincide\n",
    "        self.conv2_3 = nn.Conv2d(\n",
    "            in_channels = 32, #32 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 32, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la cuarta capa convolucional\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels = 32, #32 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 64, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la quinta capa convolucional\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels = 64, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 64, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la sexta capa convolucional\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels = 64, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 128, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la séptima (y octava y novena) capa convolucional\n",
    "        self.conv7_8_9 = nn.Conv2d(\n",
    "            in_channels = 128, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 128, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la décima capa convolucional\n",
    "        self.conv10 = nn.Conv2d(\n",
    "            in_channels = 128, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 256, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #las últimas 3 capa convolucionales\n",
    "        self.conv11_12_13 = nn.Conv2d(\n",
    "            in_channels = 256, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 256, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la función de activación (en este caso PReLU)\n",
    "        self.activation = nn.PReLU()\n",
    "        \n",
    "        #la capa de MaxPool\n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = 2, #establecemos el tamaño del kernel a 2*2\n",
    "            stride = 2 #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "        )\n",
    "        \n",
    "        #la primera capa de neuronas a la que aplicaremos Dropout como técnica de regularización\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features = 256, #número de características de entrada\n",
    "            out_features = 256 #número de neuronas de salida\n",
    "        )\n",
    "        \n",
    "        #la segunda capa fully-connected\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        \n",
    "        #la tercera capa fully-connected\n",
    "        self.fc3 = nn.Linear(128,64)\n",
    "        \n",
    "        #la capa de neuronas fully-connected final\n",
    "        self.dense = nn.Linear(\n",
    "            in_features = 64, #número de parámetros de entrada de la red (los valores se obtienen experimentalmente)\n",
    "            out_features = 5 #número de neuronas de salida\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #en esta función es donde tiene lugar la computación (y la función invocada por defecto al ejecutar la red)\n",
    "        #siguiendo la estructura descrita en Ghosh et al.:\n",
    "        \n",
    "        #primero una capa convolucional de tipo 1, con su consecuente activación PReLU y la capa de MaxPool\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        #una capa convolucional de tipo 2 con su correspondiente activación\n",
    "        x = self.activation(self.conv2_3(x))\n",
    "        #capa convolucional de tipo 2 con activación y MaxPool\n",
    "        x = self.pool(self.activation(self.conv2_3(x)))\n",
    "        #cuarta convolucional con activación\n",
    "        x = self.activation(self.conv4(x))\n",
    "        #quinta convolucional con activación y MaxPool\n",
    "        x = self.pool(self.activation(self.conv5(x)))\n",
    "        #3 capas convolucionales consecutivas de tipo 2 con su correspondiente activación\n",
    "        x = self.activation(self.conv6(x))\n",
    "        x = self.activation(self.conv7_8_9(x))\n",
    "        x = self.activation(self.conv7_8_9(x))\n",
    "        #novena capa convolucional con activación y MaxPool\n",
    "        x = self.pool(self.activation(self.conv7_8_9(x)))\n",
    "        #se repite la misma estructura de 3 capas convolucionales con activación y una última con activación y MaxPool\n",
    "        x = self.activation(self.conv10(x))\n",
    "        x = self.activation(self.conv11_12_13(x))\n",
    "        x = self.activation(self.conv11_12_13(x))\n",
    "        x = self.pool(self.activation(self.conv11_12_13(x)))\n",
    "        #aplanamos la salida, hasta convertirla de forma matricial a forma vectorial (sería la capa flatten)\n",
    "        x = x.view(-1,self.num_flat_features(x))#usamos una función propia de la clase para obtener el número de características\n",
    "        #aplicamos una primera red neuronal fully-connected, con la activación consecuente y la estrategia dropout para evitar el sobreentrenamiento\n",
    "        x = F.dropout(self.activation(self.fc1(x)))\n",
    "        #lo mismo sucede con la segunda capa fully-connected\n",
    "        x = F.dropout(self.activation(self.fc2(x)))\n",
    "        #y con la tercera\n",
    "        x = F.dropout(self.activation(self.fc3(x)))\n",
    "        #por último tiene lugar la capa de predicciones, que convierte las 512 neuronas de la tercera capa fully-connected en una salida de 5 neuronas (una por clase)\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        #por último definimos la función que permite obtener el número de características de los tensores\n",
    "        size = x.size()[1:] #seleccionamos todas las dimensiones expcepto la primera (que son los batches)\n",
    "        num_features = 1\n",
    "        #va iterando y calcula el número de características de los datos (x)\n",
    "        for s in size:\n",
    "            num_features*=s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60b8f1b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tercera_var(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))\n",
      "  (conv2_3): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv7_8_9): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv11_12_13): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (activation): PReLU(num_parameters=1)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (dense): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#creamos una instancia de esta red\n",
    "tercera = Tercera_var()\n",
    "#mostramos su estructura\n",
    "print(tercera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb6139f4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/50 - Accuracy: 0.4690265486725664 - Loss: 0.8141241669654846\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#entrenamos la red haciendo uso de la función 'entrena()' importada\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mentrena\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimera\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepocas\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\UBU\\4º curso\\TFG\\CNN_and_Diabetic_Retinopathy\\modules\\CNN_utilities.py:45\u001b[0m, in \u001b[0;36mentrena\u001b[1;34m(red, epocas, train_loader, optimizer, criterion)\u001b[0m\n\u001b[0;32m     43\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#y cargamos las imágenes de entrenamiento y sus etiquetas usando la estructura Loader pasada como parámetro\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m#obtenemos las imágenes y etiquetas del lote por separado\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m#establecemos a 0 los parámetros del modelo\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1282\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1284\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1120\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1123\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:335\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    333\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:884\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    882\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 884\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:816\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    814\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 816\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#entrenamos la red haciendo uso de la función 'entrena()' importada\n",
    "#recogemos los resultados en 2 variables que posteriormente nos permitirán representar la evolución de accuracy y loss\n",
    "acc,loss = entrena(tercera,epocas,train_loader,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5724036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#representamos la evolución temporal de accuracy\n",
    "representa_train(acc,'Accuracy','Ghosh - Tercera Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffa3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y representamos el loss\n",
    "representa_train(acc,'Loss','Ghosh - Tercera Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalmente ponemos a prueba la red usando la función tester y recogemos los resultados para obtener las métricas\n",
    "y_true_iphone, y_pred_iphone, predictions_iphone = tester(tercera,test_i_loader)\n",
    "#y posteriormente obtenemos y mostramos las métricas\n",
    "representa_test(y_true_iphone,y_pred_iphone,predictions_iphone,'iPhone','Tercera Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7bb095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repetimos el mismo proceso pero empleando el conjunto de imágenes de Samsung\n",
    "y_true_samsung, y_pred_samsung, predictions_samsung = tester(tercera,test_S_loader)\n",
    "#y posteriormente obtenemos y mostramos las métricas\n",
    "representa_test(y_true_samsung,y_pred_samsung,predictions_samsung,'Samsung','Tercera Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e828b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#Cuarta variante: 6 capas convolucionales y neuronas FC (fully-connected) 1024, 512, 256\n",
    "class Cuarta_var(nn.Module):\n",
    "    #esta estructura está formada por capas convolucionales, de maxpooling, de activación, de Dropout, fully-connected y de clasificación\n",
    "    \n",
    "    def __init__(self):\n",
    "        #sobreescribimos el constructor del padre\n",
    "        super(Cuarta_var,self).__init__()\n",
    "        #primero definimos una capa convolucional\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = 3, #3 canales de entrada porque las imágenes son a color\n",
    "            out_channels = 32, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 7, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la segunda (y tercera) capa convolucional, se pueden definir como una única porque el número de entradas y salidas coincide\n",
    "        self.conv2_3 = nn.Conv2d(\n",
    "            in_channels = 32, #32 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 32, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la cuarta capa convolucional\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels = 32, #32 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 64, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la quinta capa convolucional\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels = 64, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 64, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la sexta capa convolucional\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels = 64, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "            out_channels = 128, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "            kernel_size = 3, #suele tratarse de un número impar\n",
    "            stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "        )\n",
    "        \n",
    "        #la función de activación (en este caso PReLU)\n",
    "        self.activation = nn.PReLU()\n",
    "        \n",
    "        #la capa de MaxPool\n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = 2, #establecemos el tamaño del kernel a 2*2\n",
    "            stride = 2 #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "        )\n",
    "        \n",
    "        #la primera capa de neuronas a la que aplicaremos Dropout como técnica de regularización\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features = 1152, #número de características de entrada\n",
    "            out_features = 1024 #número de neuronas de salida\n",
    "        )\n",
    "        \n",
    "        #la segunda capa fully-connected\n",
    "        self.fc2 = nn.Linear(1024,512)\n",
    "        \n",
    "        #la tercera capa fully-connected\n",
    "        self.fc3 = nn.Linear(512,256)\n",
    "        \n",
    "        #la capa de neuronas fully-connected final\n",
    "        self.dense = nn.Linear(\n",
    "            in_features = 256, #número de parámetros de entrada de la red (los valores se obtienen experimentalmente)\n",
    "            out_features = 5 #número de neuronas de salida\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #en esta función es donde tiene lugar la computación (y la función invocada por defecto al ejecutar la red)\n",
    "        #siguiendo la estructura descrita en Ghosh et al.:\n",
    "        \n",
    "        #primero una capa convolucional de tipo 1, con su consecuente activación PReLU y la capa de MaxPool\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        #una capa convolucional de tipo 2 con su correspondiente activación\n",
    "        x = self.activation(self.conv2_3(x))\n",
    "        #capa convolucional de tipo 2 con activación y MaxPool\n",
    "        x = self.pool(self.activation(self.conv2_3(x)))\n",
    "        #cuarta convolucional con activación\n",
    "        x = self.activation(self.conv4(x))\n",
    "        #quinta convolucional con activación y MaxPool\n",
    "        x = self.pool(self.activation(self.conv5(x)))\n",
    "        #una última capa convolucional con su correspondiente activación\n",
    "        x = self.activation(self.conv6(x))\n",
    "        #aplanamos la salida, hasta convertirla de forma matricial a forma vectorial (sería la capa flatten)\n",
    "        x = x.view(-1,self.num_flat_features(x))#usamos una función propia de la clase para obtener el número de características\n",
    "        #aplicamos una primera red neuronal fully-connected, con la activación consecuente y la estrategia dropout para evitar el sobreentrenamiento\n",
    "        x = F.dropout(self.activation(self.fc1(x)))\n",
    "        #lo mismo sucede con la segunda capa fully-connected\n",
    "        x = F.dropout(self.activation(self.fc2(x)))\n",
    "        #y con la tercera\n",
    "        x = F.dropout(self.activation(self.fc3(x)))\n",
    "        #por último tiene lugar la capa de predicciones, que convierte las 512 neuronas de la tercera capa fully-connected en una salida de 5 neuronas (una por clase)\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        #por último definimos la función que permite obtener el número de características de los tensores\n",
    "        size = x.size()[1:] #seleccionamos todas las dimensiones expcepto la primera (que son los batches)\n",
    "        num_features = 1\n",
    "        #va iterando y calcula el número de características de los datos (x)\n",
    "        for s in size:\n",
    "            num_features*=s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b85c6cb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuarta_var(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))\n",
      "  (conv2_3): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (conv6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "  (activation): PReLU(num_parameters=1)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1152, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (dense): Linear(in_features=256, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#creamos una instancia de esta red\n",
    "cuarta = Cuarta_var()\n",
    "#mostramos su estructura\n",
    "print(cuarta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "423fc89d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/50 - Accuracy: 0.07079646017699115 - Loss: 1.6384624242782593\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#entrenamos la red haciendo uso de la función 'entrena()' importada\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#recogemos los resultados en 2 variables que posteriormente nos permitirán representar la evolución de accuracy y loss\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m acc,loss \u001b[38;5;241m=\u001b[39m \u001b[43mentrena\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuarta\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepocas\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\UBU\\4º curso\\TFG\\CNN_and_Diabetic_Retinopathy\\modules\\CNN_utilities.py:45\u001b[0m, in \u001b[0;36mentrena\u001b[1;34m(red, epocas, train_loader, optimizer, criterion)\u001b[0m\n\u001b[0;32m     43\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#y cargamos las imágenes de entrenamiento y sus etiquetas usando la estructura Loader pasada como parámetro\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m#obtenemos las imágenes y etiquetas del lote por separado\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m#establecemos a 0 los parámetros del modelo\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1282\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1284\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1120\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1123\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:335\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    333\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:884\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    882\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 884\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_py39\\lib\\multiprocessing\\connection.py:816\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    814\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 816\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#entrenamos la red haciendo uso de la función 'entrena()' importada\n",
    "#recogemos los resultados en 2 variables que posteriormente nos permitirán representar la evolución de accuracy y loss\n",
    "acc,loss = entrena(cuarta,epocas,train_loader,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#representamos la evolución temporal de accuracy\n",
    "representa_train(acc,'Accuracy','Ghosh - Cuarta Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e996feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y representamos el loss\n",
    "representa_train(acc,'Loss','Ghosh - Cuarta Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8df324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalmente ponemos a prueba la red usando la función tester y recogemos los resultados para obtener las métricas\n",
    "y_true_iphone, y_pred_iphone, predictions_iphone = tester(cuarta,test_i_loader)\n",
    "#y posteriormente obtenemos y mostramos las métricas\n",
    "representa_test(y_true_iphone,y_pred_iphone,predictions_iphone,'iPhone','Cuarta Variante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04cf615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repetimos el mismo proceso pero empleando el conjunto de imágenes de Samsung\n",
    "y_true_samsung, y_pred_samsung, predictions_samsung = tester(cuarta,test_S_loader)\n",
    "#y posteriormente obtenemos y mostramos las métricas\n",
    "representa_test(y_true_samsung,y_pred_samsung,predictions_samsung,'Samsung','Cuarta Variante')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
