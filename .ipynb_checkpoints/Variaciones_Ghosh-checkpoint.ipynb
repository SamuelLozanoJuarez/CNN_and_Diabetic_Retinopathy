{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84081677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#primero importamos todos los paquetes necesarios\n",
    "import torch #contiene todas las funciones de PyTorch\n",
    "import torch.nn as nn #contiene la clase padre de todos los modelos (nn.Module)\n",
    "import torch.nn.functional as F #esencial para la función de activación \n",
    "import torchvision #fundamental para la importación de imágenes\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt #para poder representar las gráficas\n",
    "import numpy as np #para las métricas de la red\n",
    "\n",
    "#importamos también las funcioness definidas para el entrenamiento y puesta a prueba de los modelos\n",
    "from modules.CNN_utilities import entrena, representa_test, representa_train, tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6f6d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de datos de train: 113\n",
      "Tamaño del conjunto de datos de test de Samsung: 93\n",
      "Tamaño del conjunto de datos de test de iPhone: 99\n"
     ]
    }
   ],
   "source": [
    "#establecemos el tamaño del batch, la escala de las imágenes y el número de épocas de entrenamiento\n",
    "batch = 4\n",
    "#la arquitectura propuesta por Ghosh requiere una escala de 512, 512, 3\n",
    "escala = 512\n",
    "epocas = 50\n",
    "\n",
    "#a continuación definimos la operación que permitirá transformar las imágenes del repositorio en Tensores que puedan ser empleados por PyTorch\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), #transforma la imagen de formato PIL a formato tensor\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), #normaliza el tensor para que la media de sus valores sea 0 y su desviación estándar 0.5\n",
    "     transforms.Resize((escala, escala))]) #redimensionamos las imágenes\n",
    "\n",
    "#a continuación cargamos el conjunto de imágenes de train (OCT) y los dos de test (iPhone y Samsung)\n",
    "OCT = ImageFolder(root = 'Datos/Classified Data/Images/OCT', transform = transform)\n",
    "print(f'Tamaño del conjunto de datos de train: {len(OCT)}')\n",
    "\n",
    "Samsung = ImageFolder(root = 'Datos/Classified Data/Images/Samsung', transform = transform)\n",
    "print(f'Tamaño del conjunto de datos de test de Samsung: {len(Samsung)}')\n",
    "\n",
    "iPhone = ImageFolder(root = 'Datos/Classified Data/Images/iPhone', transform = transform)\n",
    "print(f'Tamaño del conjunto de datos de test de iPhone: {len(iPhone)}')\n",
    "\n",
    "#establecemos una lista con el nombre de las etiquetas\n",
    "classes = OCT.classes\n",
    "\n",
    "#y definimos también las funciones que van a ir cargando las imágenes en el modelo\n",
    "train_loader = DataLoader(\n",
    "    dataset = OCT,\n",
    "    batch_size = 4, #establecemos un tamaño de lote (batch_size) de 4, ya que son pocas imágenes y podemos permitírnoslo\n",
    "    shuffle = True, #indicamos que mezcle las imágenes\n",
    "    num_workers = 2 #genera subprocesos para cargar los datos y así liberamos el proceso main\n",
    ")\n",
    "\n",
    "test_S_loader = DataLoader(\n",
    "    dataset = Samsung,\n",
    "    batch_size = 4, #establecemos un tamaño de lote (batch_size) de 10, ya que son pocas imágenes y podemos permitírnoslo\n",
    "    shuffle = True, #indicamos que mezcle las imágenes\n",
    "    num_workers = 2 #genera subprocesos para cargar los datos y así liberamos el proceso main\n",
    ")\n",
    "\n",
    "test_i_loader = DataLoader(\n",
    "    dataset = iPhone,\n",
    "    batch_size = 4, #establecemos un tamaño de lote (batch_size) de 10, ya que son pocas imágenes y podemos permitírnoslo\n",
    "    shuffle = True, #indicamos que mezcle las imágenes\n",
    "    num_workers = 2 #genera subprocesos para cargar los datos y así liberamos el proceso main\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45cd4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A lo largo de este script voy a probar a variar algunos parámetros del modelo (intentando no perder la esencia de la estructura original)\n",
    "#Los parámetros modificados serán los siguientes:\n",
    "# - número de capas convolucionales (6, 9 o 13)\n",
    "# - número de filtros por capa (conservando los originales, reduciéndolos a la mitad o multiplicándolos por dos)\n",
    "# - número de neuronas de las capas fully-connected, probando las siguientes combinaciones:\n",
    "#    * 256/1024/512\n",
    "#    * 128/512/256\n",
    "#    * 64/256/128\n",
    "#    * 128/256/512\n",
    "#    * 512/256/128\n",
    "# Por tanto el número total de posibles combinaciones es 3*3*5 = 45 combinaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb3fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para facilitar la lectura del código y sobre todo su ejecución, voy a definir una función que permita lanzar las ejecuciones necesarias de manera automática"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3cafc",
   "metadata": {},
   "source": [
    "FALTA MODIFICAR EL FORWARD PARA INCLUIR SOLO LAS CAPAS NECESARIAS Y MODIFICAR EL IN_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b38319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crea_Ghosh(capas_conv, filtros, neuronas):\n",
    "    '''\n",
    "    Función que crea una red siguiendo la arquitectura Ghosh pero con las características introducidas como parámetros.\n",
    "    \n",
    "    Parámetros\n",
    "    --------------------------------------------------------------------------\n",
    "    capas_conv: número entero que puede tomar 3 posibles valores (6, 9 o 13) y que representa el número de capas convolucionales que tiene la red.\n",
    "    filtros: float que representa el número de filtros por capa convolucional. Puede ser 1.0 si conserva el número original, 0.5 si lo divide a la mitad y 2.0 si lo duplica.\n",
    "    neuronas: String que contiene el número de neuronas de las capas fully-connected separados por barras laterales (/).\n",
    "    \n",
    "    Return\n",
    "    --------------------------------------------------------------------------\n",
    "    modelo: devuelve una instancia de la clase Ghosh con las características arquitectónicas deseadas, es decir, un modelo de CNN con las características indicadas en los parámetros.\n",
    "    '''\n",
    "    #primero definimos la clase correspondiente (Ghosh en este caso), incluyendo los elementos necesarios para obtener las variaciones deseadas\n",
    "    class Ghosh(nn.Module):\n",
    "        #esta estructura está formada por capas convolucionales, de maxpooling, de activación, de Dropout, fully-connected y de clasificación\n",
    "\n",
    "        def __init__(self):\n",
    "            #sobreescribimos el constructor del padre\n",
    "            super(Ghosh,self).__init__()\n",
    "            #primero definimos una capa convolucional\n",
    "            #el número de filtros de cada capa irá multiplicado por el parámetro filtros (para reducirlo, duplicarlo o mantenerlo)\n",
    "            self.conv1 = nn.Conv2d(\n",
    "                in_channels = 3, #3 canales de entrada porque las imágenes son a color\n",
    "                out_channels = 32*filtros, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                kernel_size = 7, #suele tratarse de un número impar\n",
    "                stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "            )\n",
    "\n",
    "            #la segunda (y tercera) capa convolucional, se pueden definir como una única porque el número de entradas y salidas coincide\n",
    "            self.conv2_3 = nn.Conv2d(\n",
    "                in_channels = 32*filtros, #32 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                out_channels = 32*filtros, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                kernel_size = 3, #suele tratarse de un número impar\n",
    "                stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "            )\n",
    "\n",
    "            #la cuarta capa convolucional\n",
    "            self.conv4 = nn.Conv2d(\n",
    "                in_channels = 32*filtros, #32 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                out_channels = 64*filtros, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                kernel_size = 3, #suele tratarse de un número impar\n",
    "                stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "            )\n",
    "\n",
    "            #la quinta capa convolucional\n",
    "            self.conv5 = nn.Conv2d(\n",
    "                in_channels = 64*filtros, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                out_channels = 64*filtros, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                kernel_size = 3, #suele tratarse de un número impar\n",
    "                stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "            )\n",
    "\n",
    "            #la sexta capa convolucional\n",
    "            self.conv6 = nn.Conv2d(\n",
    "                in_channels = 64*filtros, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                out_channels = 128*filtros, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                kernel_size = 3, #suele tratarse de un número impar\n",
    "                stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "            )\n",
    "            \n",
    "            #comprobamos el número de capas introducidas como parámetros\n",
    "            if capas_conv > 6:\n",
    "                #la séptima (y octava y novena) capa convolucional\n",
    "                self.conv7_8_9 = nn.Conv2d(\n",
    "                    in_channels = 128*filtros, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                    out_channels = 128*filtros, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                    kernel_size = 3, #suele tratarse de un número impar\n",
    "                    stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                    padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "                )\n",
    "                \n",
    "                #nuevamente comprobamos antes de incluir las últimas 4 capas\n",
    "                if capas_conv > 9:\n",
    "                    #la décima capa convolucional\n",
    "                    self.conv10 = nn.Conv2d(\n",
    "                        in_channels = 128*filtros, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                        out_channels = 256*filtros, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                        kernel_size = 3, #suele tratarse de un número impar\n",
    "                        stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                        padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "                    )\n",
    "\n",
    "                    #las últimas 3 capa convolucionales\n",
    "                    self.conv11_12_13 = nn.Conv2d(\n",
    "                        in_channels = 256*filtros, #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                        out_channels = 256*filtros, #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                        kernel_size = 3, #suele tratarse de un número impar\n",
    "                        stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                        padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "                    )\n",
    "\n",
    "            #la función de activación (en este caso PReLU)\n",
    "            self.activation = nn.PReLU()\n",
    "\n",
    "            #la capa de MaxPool\n",
    "            self.pool = nn.MaxPool2d(\n",
    "                kernel_size = 2, #establecemos el tamaño del kernel a 2*2\n",
    "                stride = 2 #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            )\n",
    "            \n",
    "            #REVISAR TODO ESTO, QUE NO ME FÍO YO MUCHO DE CÓMO LO HA SACADO CHATGPT\n",
    "            #debido a que el número de neuronas de entrada de la capa fully-connected dependerá del número de neuronas de salida vamos a definir este valor\n",
    "            #AQUÍ HAY QUE VER CÓMO SE DEFINE ESE VALOR (y asignárselo a la variable neuronas_entrada)\n",
    "            #el número de características es la salida de la capa anterior (out_channels*escala*escala de la imagen tras la capa anterior)\n",
    "            #para saber las dimensiones de una imagen tras pasar por una capa convolucional: output_size = ((input_size + 2*padding - kernel_size) / stride)\n",
    "            #esta fórmula deriva de la operación de convolución y se emplea en muchos papers y libros, por ejemplo:\n",
    "            # \"Deep Learning for Computer Vision\" de Rajalingappaa Shanmugamani, en el capítulo 3 \"Convolutional Neural Networks\"\n",
    "            \n",
    "            #la primera capa de neuronas a la que aplicaremos Dropout como técnica de regularización\n",
    "            self.fc1 = nn.Linear(\n",
    "                in_features = neuronas_entrada, #número de características de entrada\n",
    "                out_features = int(neuronas.split('/')[0]) #número de neuronas de salida, obtenidas del parámetro pasado\n",
    "            )\n",
    "\n",
    "            #la segunda capa fully-connected\n",
    "            self.fc2 = nn.Linear(int(neuronas.split('/')[0]),int(neuronas.split('/')[1]))\n",
    "\n",
    "            #la tercera capa fully-connected\n",
    "            self.fc3 = nn.Linear(int(neuronas.split('/')[1]),int(neuronas.split('/')[2]))\n",
    "\n",
    "            #la capa de neuronas fully-connected final\n",
    "            self.dense = nn.Linear(\n",
    "                in_features = int(neuronas.split('/')[2]), \n",
    "                out_features = 5 #número de neuronas de salida (número de etiquetas del problema)\n",
    "            )\n",
    "\n",
    "        def forward(self,x):\n",
    "            #en esta función es donde tiene lugar la computación (y la función invocada por defecto al ejecutar la red)\n",
    "            #siguiendo la estructura descrita en Ghosh et al. (con sus respectivas variaciones):\n",
    "\n",
    "            #primero una capa convolucional de tipo 1, con su consecuente activación PReLU y la capa de MaxPool\n",
    "            x = self.pool(self.activation(self.conv1(x)))\n",
    "            #una capa convolucional de tipo 2 con su correspondiente activación\n",
    "            x = self.activation(self.conv2_3(x))\n",
    "            #capa convolucional de tipo 2 con activación y MaxPool\n",
    "            x = self.pool(self.activation(self.conv2_3(x)))\n",
    "            #cuarta convolucional con activación\n",
    "            x = self.activation(self.conv4(x))\n",
    "            #quinta convolucional con activación y MaxPool\n",
    "            x = self.pool(self.activation(self.conv5(x)))\n",
    "            #3 capas convolucionales consecutivas de tipo 2 con su correspondiente activación\n",
    "            x = self.activation(self.conv6(x))\n",
    "            if capas_conv > 6:\n",
    "                x = self.activation(self.conv7_8_9(x))\n",
    "                x = self.activation(self.conv7_8_9(x))\n",
    "                #novena capa convolucional con activación y MaxPool\n",
    "                x = self.pool(self.activation(self.conv7_8_9(x)))\n",
    "                if capas_conv > 9:\n",
    "                    #se repite la misma estructura de 3 capas convolucionales con activación y una última con activación y MaxPool\n",
    "                    x = self.activation(self.conv10(x))\n",
    "                    x = self.activation(self.conv11_12_13(x))\n",
    "                    x = self.activation(self.conv11_12_13(x))\n",
    "                    x = self.pool(self.activation(self.conv11_12_13(x)))\n",
    "            #aplanamos la salida, hasta convertirla de forma matricial a forma vectorial (sería la capa flatten)\n",
    "            x = x.view(-1,self.num_flat_features(x))#usamos una función propia de la clase para obtener el número de características\n",
    "            #aplicamos una primera red neuronal fully-connected, con la activación consecuente y la estrategia dropout para evitar el sobreentrenamiento\n",
    "            x = F.dropout(self.activation(self.fc1(x)))\n",
    "            #lo mismo sucede con la segunda capa fully-connected\n",
    "            x = F.dropout(self.activation(self.fc2(x)))\n",
    "            #y con la tercera\n",
    "            x = F.dropout(self.activation(self.fc3(x)))\n",
    "            #por último tiene lugar la capa de predicciones, que convierte las 512 neuronas de la tercera capa fully-connected en una salida de 5 neuronas (una por clase)\n",
    "            x = self.dense(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "        def num_flat_features(self,x):\n",
    "            #por último definimos la función que permite obtener el número de características de los tensores\n",
    "            size = x.size()[1:] #seleccionamos todas las dimensiones expcepto la primera (que son los batches)\n",
    "            num_features = 1\n",
    "            #va iterando y calcula el número de características de los datos (x)\n",
    "            for s in size:\n",
    "                num_features*=s\n",
    "            return num_features\n",
    "\n",
    "    #por último creamos una instancia de esta red\n",
    "    modelo = Ghosh()\n",
    "    #y la devolvemos\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28a350d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_dim(num_capas):\n",
    "    size = 512\n",
    "    if num_capas >= 6:\n",
    "        size = funcion(size,7,2,2) #tras primera capa conv\n",
    "        for i in range(5):\n",
    "            size = funcion(size,3,2,2) #tras segunda-sexta capa conv\n",
    "        if num_capas >= 9:\n",
    "            for i in range(3):\n",
    "                size = funcion(size,3,2,2) #tras séptima-novena capa conv\n",
    "            if num_capas == 13:\n",
    "                for i in range(3):\n",
    "                    size = funcion(size,3,2,2)\n",
    "    return round(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0c7c110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcula_dim(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5591a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion(input_size,kernel_size,stride,padding):\n",
    "    return ((input_size + 2*padding - kernel_size) / stride)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
