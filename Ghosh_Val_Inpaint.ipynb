{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594af840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\venv_py39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#########################################################################################################################\n",
    "INFORMACIÓN DEL FICHERO\n",
    "#########################################################################################################################\n",
    "\n",
    "Autor: Samuel Lozano Juárez\n",
    "Fecha: 20/04/2023\n",
    "Institución: UBU | Grado en Ingeniería de la Salud\n",
    "\n",
    "Este archivo forma parte del Trabajo de Fin de Grado \"Detección del grado de retinopatía mediante redes convolucionales\".\n",
    "El alumno a cargo de este proyecto es el declarado como autor en las líneas anteriores.\n",
    "Los tutores del proyecto fueron el Dr. Darío Fernández Zoppino y el Dr. Daniel Urda Muñoz.\n",
    "\n",
    "A continuación se incluye el código que permite crear varios modelos según la arquitectura propuesta en el artículo de Ghosh, pero realizando las modificacionesdeseadas en los parámetros (número de capas convolucionales de la arquitectura, número de filtros por capa  y número de neuronas de las capas fully-connected).\n",
    "Para el entrenamiento se usará un conjunto de datos de validación y se empleará la estrategia de Early Stopping, para evitar el sobreentrenamiento.\n",
    "Todas estas arquitecturas serán entrenadas y testeadas, y sus resultados se almacenarán automáticamente en un archivo .csv llamado Resultados.\n",
    "Además también se guardarán el estado de los modelos (sus pesos) por si quisieran reutilizarse.\n",
    "'''\n",
    "\n",
    "#primero importamos todos los paquetes necesarios\n",
    "import torch #contiene todas las funciones de PyTorch\n",
    "import torch.nn as nn #contiene la clase padre de todos los modelos (nn.Module)\n",
    "import torch.nn.functional as F #esencial para la función de activación \n",
    "import torchvision #fundamental para la importación de imágenes\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt #para poder representar las gráficas\n",
    "import numpy as np #para las métricas de la red\n",
    "\n",
    "#importamos también las funcioness definidas para el entrenamiento y puesta a prueba de los modelos\n",
    "from modules.CNN_utilities import entrena_val, representa_test, obtiene_metricas, tester, guarda_graficas\n",
    "\n",
    "#importamos el paquete para el cálculo del tiempo\n",
    "import time\n",
    "\n",
    "#establecemos el tamaño del batch, la escala de las imágenes y el número de épocas de entrenamiento\n",
    "batch = 4\n",
    "#la arquitectura propuesta por Ghosh requiere una escala de 512, 512, 3\n",
    "escala = 512\n",
    "epocas = 150 #ya que tenemos activado el Early Stopping\n",
    "\n",
    "#a continuación definimos la operación que permitirá transformar las imágenes del repositorio en Tensores que puedan ser empleados por PyTorch\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), #transforma la imagen de formato PIL a formato tensor\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), #normaliza el tensor para que la media de sus valores sea 0 y su desviación estándar 0.5\n",
    "     transforms.Resize((escala, escala))]) #redimensionamos las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e80ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de datos de train: 113\n"
     ]
    }
   ],
   "source": [
    "#a continuación cargamos el conjunto de imágenes de train (OCT) y los dos de test (iPhone y Samsung)\n",
    "OCT = ImageFolder(root = 'Datos/Classified Data/Images/OCT', transform = transform)\n",
    "print(f'Tamaño del conjunto de datos de train: {len(OCT)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1b1170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de datos de test de Samsung: 93\n",
      "Tamaño del conjunto de datos de test de iPhone: 99\n"
     ]
    }
   ],
   "source": [
    "Samsung = ImageFolder(root = 'Datos/Classified Data/Images/Samsung/Inpaint', transform = transform)\n",
    "print(f'Tamaño del conjunto de datos de test de Samsung: {len(Samsung)}')\n",
    "\n",
    "iPhone = ImageFolder(root = 'Datos/Classified Data/Images/iPhone/Inpaint', transform = transform)\n",
    "print(f'Tamaño del conjunto de datos de test de iPhone: {len(iPhone)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8ca819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establecemos una lista con el nombre de las etiquetas\n",
    "classes = OCT.classes\n",
    "\n",
    "#en esta ocasión, debido a que vamos a implementar EarlyStopping es necesario dividir el conjunto de entrenamiento en train y validation\n",
    "#Dividimos el conjunto de datos en entrenamiento y validación (80% y 20% respectivamente)\n",
    "train_size = int(0.8 * len(OCT))\n",
    "val_size = len(OCT) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(OCT, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61783d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear cargadores de datos para cada conjunto\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch, \n",
    "    shuffle = True,\n",
    "    num_workers = 2 #genera subprocesos para cargar los datos y así liberamos el proceso main\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset = val_dataset,\n",
    "    batch_size = batch,\n",
    "    shuffle = True,\n",
    "    num_workers = 2\n",
    ")\n",
    "\n",
    "test_S_loader = DataLoader(\n",
    "    dataset = Samsung,\n",
    "    batch_size = batch, #establecemos un tamaño de lote (batch_size) de 4, ya que son pocas imágenes y podemos permitírnoslo\n",
    "    shuffle = True, #indicamos que mezcle las imágenes\n",
    "    num_workers = 2 #genera subprocesos para cargar los datos y así liberamos el proceso main\n",
    ")\n",
    "\n",
    "test_i_loader = DataLoader(\n",
    "    dataset = iPhone,\n",
    "    batch_size = batch, #establecemos un tamaño de lote (batch_size) de 4, ya que son pocas imágenes y podemos permitírnoslo\n",
    "    shuffle = True, #indicamos que mezcle las imágenes\n",
    "    num_workers = 2 #genera subprocesos para cargar los datos y así liberamos el proceso main\n",
    ")\n",
    "\n",
    "#A lo largo de este script voy a probar a variar algunos parámetros del modelo (intentando no perder la esencia de la estructura original)\n",
    "#Los parámetros modificados serán los siguientes:\n",
    "# - número de capas convolucionales (6, 9 o 13)\n",
    "# - número de filtros por capa (conservando los originales, reduciéndolos a la mitad o multiplicándolos por dos)\n",
    "# - número de neuronas de las capas fully-connected, probando las siguientes combinaciones:\n",
    "#    * 256/1024/512\n",
    "#    * 128/512/256\n",
    "#    * 64/256/128\n",
    "#    * 128/256/512\n",
    "#    * 512/256/128\n",
    "# Por tanto el número total de posibles combinaciones es 3*3*5 = 45 combinaciones\n",
    "\n",
    "#Para facilitar la lectura del código y sobre todo su ejecución, voy a definir una función que permita lanzar las ejecuciones necesarias de manera automática\n",
    "\n",
    "def crea_Ghosh(capas_conv, filtros, neuronas):\n",
    "    '''\n",
    "    Función que crea una red siguiendo la arquitectura Ghosh pero con las características introducidas como parámetros.\n",
    "    \n",
    "    Parámetros\n",
    "    --------------------------------------------------------------------------\n",
    "    capas_conv: número entero que puede tomar 3 posibles valores (6, 9 o 13) y que representa el número de capas convolucionales que tiene la red.\n",
    "    filtros: float que representa el número de filtros por capa convolucional. Puede ser 1.0 si conserva el número original, 0.5 si lo divide a la mitad y 2.0 si lo duplica.\n",
    "    neuronas: String que contiene el número de neuronas de las capas fully-connected separados por barras laterales (/).\n",
    "    \n",
    "    Return\n",
    "    --------------------------------------------------------------------------\n",
    "    modelo: devuelve una instancia de la clase Ghosh con las características arquitectónicas deseadas, es decir, un modelo de CNN con las características indicadas en los parámetros.\n",
    "    '''\n",
    "    \n",
    "    #Debido a las distintas variaciones que se van a producir en la arquitectura, el número de características (y por tanto de neuronas) variará.\n",
    "    #Es por ello que para simplificar esta labor voy a definir 2 funciones que permiten calcular el número de características resultantes tras las capas convolucionales y de MaxPooling.\n",
    "    #De esta manera se podrá pasar este valor como parámetro in_features a la primera capa fully-connected.\n",
    "\n",
    "    #Sabemos que el número de características tras una capa convolucional se corresponde con la siguiente fórmula:\n",
    "    #    features = num_filtros*ancho*alto\n",
    "    #Tal y como se describe en el capítulo \"Convolutional Neural Networks\" en el libro \"Deep Learning\" de Ian Goodfellow, Yoshua Bengio y Aaron Courville\n",
    "\n",
    "    #El número de filtros lo podemos obtener de la última capa convolucional, pero el ancho y alto de la imagen variarán tras cada capa.\n",
    "    #Las dimensiones modificadas tras una capa convolucional y de maxpooling se pueden calcular gracias a la siguiente ecuación:\n",
    "    #    output_size = (input_size-2*padding-kernel_size)/stride + 1\n",
    "    #Tal y como se describe en el capítulo 3 \"Convolutional Neural Networks\" del libro \"Deep Learning for Computer Vision\" de Rajalingappaa Shanmugamani\n",
    "\n",
    "    #Sabiendo esto ya podemos definir las funciones que permiten calcular las dimensiones\n",
    "    def funcion(input_size,kernel_size,stride,padding):\n",
    "        '''\n",
    "        Aplica la ecuación para calcular las dimensiones tras una capa convolucional/maxpooling descrita en el libro Deep Learning for Computer Vision.\n",
    "\n",
    "        Parámetros\n",
    "        ----------------------------------------------------\n",
    "        input_size: número entero que se corresponde con la escala de la imagen inicial, previa a la capa convolucional.\n",
    "        kernel_size: número entero que representa el tamaño del filtro de la capa.\n",
    "        stride:  número entero que representa el desplazamiento del filtro sobre la imagen.\n",
    "        padding: número entero correspondiente al número de píxeles de relleno.\n",
    "\n",
    "        Return\n",
    "        ----------------------------------------------------\n",
    "        Devuelve un número flotante correspondiente al tamaño de la imagen una vez modificada por la capa convolucional/maxpooling.\n",
    "        '''\n",
    "        #aplicamos la fórmula\n",
    "        return ((input_size + 2*padding - kernel_size)/stride + 1)\n",
    "\n",
    "    def calcula_dim(num_capas):\n",
    "        '''\n",
    "        Calcula la escala de una imagen tras haber sido transformada por n capas convolucionales y de maxpooling, según las características de la arquitectura Ghosh.\n",
    "\n",
    "        Parámetros\n",
    "        ----------------------------------------------------\n",
    "        num_capas:\n",
    "\n",
    "        Return\n",
    "        ----------------------------------------------------\n",
    "        Devuelve un número entero correspondiente a la escala de la imagen después de todas las capas convolucionales y de maxpooling.\n",
    "        '''\n",
    "        #el tamaño inicial de las imágenes es de 512x512 (la escala original)\n",
    "        size = 512\n",
    "\n",
    "        #vamos actualizando el tamaño de la imagen según vaya atravesando capas convolucionales y de maxpooling\n",
    "        size = funcion(size,7,2,2)#tras primera capa convolucional\n",
    "        size = funcion(size,2,2,0)#tras maxpool\n",
    "        size = funcion(size,3,2,2)#tras segunda capa convolucional\n",
    "        size = funcion(size,3,2,2)#tras tercera capa convolucional\n",
    "        size = funcion(size,2,2,0)#tras maxpool\n",
    "        size = funcion(size,3,2,2)#tras cuarta capa convolucional\n",
    "        size = funcion(size,3,2,2)#tras quinta capa convolucional\n",
    "        size = funcion(size,2,2,0)#tras maxpool\n",
    "        size = funcion(size,3,2,2)#tras sexta capa convolucional\n",
    "        if num_capas > 6:\n",
    "            size = funcion(size,3,2,2)#tras séptima capa convolucional\n",
    "            size = funcion(size,3,2,2)#tras octava capa convolucional\n",
    "            size = funcion(size,3,2,2)#tras novena capa convolucional\n",
    "            size = funcion(size,2,2,0)#tras maxpool\n",
    "            if num_capas >9:\n",
    "                size = funcion(size,3,2,2)#tras décima capa convolucional\n",
    "                size = funcion(size,3,2,2)#tras decimoprimera capa convolucional\n",
    "                size = funcion(size,3,2,2)#tras decimosegunda capa convolucional\n",
    "                size = funcion(size,3,2,2)#tras decimotercera capa convolucional\n",
    "                size = funcion(size,2,2,0)#tras maxpool\n",
    "\n",
    "        return int(size)\n",
    "\n",
    "    #primero definimos la clase correspondiente (Ghosh en este caso), incluyendo los elementos necesarios para obtener las variaciones deseadas\n",
    "    class Ghosh(nn.Module):\n",
    "        #esta estructura está formada por capas convolucionales, de maxpooling, de activación, de Dropout, fully-connected y de clasificación\n",
    "\n",
    "        def __init__(self):\n",
    "            #sobreescribimos el constructor del padre\n",
    "            super(Ghosh,self).__init__()\n",
    "            #primero definimos una capa convolucional\n",
    "            #el número de filtros de cada capa irá multiplicado por el parámetro filtros (para reducirlo, duplicarlo o mantenerlo)\n",
    "            self.conv1 = nn.Conv2d(\n",
    "                in_channels = 3, #3 canales de entrada porque las imágenes son a color\n",
    "                out_channels = int(32*filtros), #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                kernel_size = 7, #suele tratarse de un número impar\n",
    "                stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "            )\n",
    "\n",
    "            #la segunda (y tercera) capa convolucional, se pueden definir como una única porque el número de entradas y salidas coincide\n",
    "            self.conv2_3 = nn.Conv2d(\n",
    "                in_channels = int(32*filtros), #32 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                out_channels = int(32*filtros), #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                kernel_size = 3, #suele tratarse de un número impar\n",
    "                stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "            )\n",
    "\n",
    "            #la cuarta capa convolucional\n",
    "            self.conv4 = nn.Conv2d(\n",
    "                in_channels = int(32*filtros), #32 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                out_channels = int(64*filtros), #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                kernel_size = 3, #suele tratarse de un número impar\n",
    "                stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "            )\n",
    "\n",
    "            #la quinta capa convolucional\n",
    "            self.conv5 = nn.Conv2d(\n",
    "                in_channels = int(64*filtros), #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                out_channels = int(64*filtros), #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                kernel_size = 3, #suele tratarse de un número impar\n",
    "                stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "            )\n",
    "\n",
    "            #la sexta capa convolucional\n",
    "            self.conv6 = nn.Conv2d(\n",
    "                in_channels = int(64*filtros), #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                out_channels = int(128*filtros), #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                kernel_size = 3, #suele tratarse de un número impar\n",
    "                stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "            )\n",
    "            \n",
    "            #comprobamos el número de capas introducidas como parámetros\n",
    "            if capas_conv > 6:\n",
    "                #la séptima (y octava y novena) capa convolucional\n",
    "                self.conv7_8_9 = nn.Conv2d(\n",
    "                    in_channels = int(128*filtros), #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                    out_channels = int(128*filtros), #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                    kernel_size = 3, #suele tratarse de un número impar\n",
    "                    stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                    padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "                )\n",
    "                \n",
    "                #nuevamente comprobamos antes de incluir las últimas 4 capas\n",
    "                if capas_conv > 9:\n",
    "                    #la décima capa convolucional\n",
    "                    self.conv10 = nn.Conv2d(\n",
    "                        in_channels = int(128*filtros), #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                        out_channels = int(256*filtros), #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                        kernel_size = 3, #suele tratarse de un número impar\n",
    "                        stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                        padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "                    )\n",
    "\n",
    "                    #las últimas 3 capa convolucionales\n",
    "                    self.conv11_12_13 = nn.Conv2d(\n",
    "                        in_channels = int(256*filtros), #64 canales de entrada para que coincida con las salidas de la capa anterior\n",
    "                        out_channels = int(256*filtros), #se trata del número de salidas de la capa. Es el número de kernels de la capa\n",
    "                        kernel_size = 3, #suele tratarse de un número impar\n",
    "                        stride = 2, #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "                        padding = 2, #cantidad de relleno que se va a aplicar sobre los bordes de la imagen\n",
    "                    )\n",
    "\n",
    "            #la función de activación (en este caso PReLU)\n",
    "            self.activation = nn.PReLU()\n",
    "\n",
    "            #la capa de MaxPool\n",
    "            self.pool = nn.MaxPool2d(\n",
    "                kernel_size = 2, #establecemos el tamaño del kernel a 2*2\n",
    "                stride = 2 #cantidad píxeles que se desplaza el filtro sobre la imagen\n",
    "            )\n",
    "            \n",
    "            #usando la función descrita anteriormente y la ecuación features = num_filtros*ancho*alto podemos calcular el número de características\n",
    "            #si tenemos 6 o 9 capas convolucionales el número de filtros de salida será 128*filtros\n",
    "            if capas_conv == 6:\n",
    "                neuronas_entrada = int(128*filtros)*calcula_dim(capas_conv)*calcula_dim(capas_conv)\n",
    "            elif capas_conv == 9:\n",
    "                neuronas_entrada = int(128*filtros)*calcula_dim(capas_conv)*calcula_dim(capas_conv)\n",
    "            #si tenemos 13 capas convolucionales el número de filtros de salida será 256*filtros\n",
    "            else:\n",
    "                neuronas_entrada = int(256*filtros)*calcula_dim(capas_conv)*calcula_dim(capas_conv)\n",
    "                \n",
    "            #la primera capa de neuronas a la que aplicaremos Dropout como técnica de regularización\n",
    "            self.fc1 = nn.Linear(\n",
    "                in_features = neuronas_entrada, #número de características de entrada\n",
    "                out_features = int(neuronas.split('/')[0]) #número de neuronas de salida, obtenidas del parámetro pasado\n",
    "            )\n",
    "\n",
    "            #la segunda capa fully-connected\n",
    "            self.fc2 = nn.Linear(int(neuronas.split('/')[0]),int(neuronas.split('/')[1]))\n",
    "\n",
    "            #la tercera capa fully-connected\n",
    "            self.fc3 = nn.Linear(int(neuronas.split('/')[1]),int(neuronas.split('/')[2]))\n",
    "\n",
    "            #la capa de neuronas fully-connected final\n",
    "            self.dense = nn.Linear(\n",
    "                in_features = int(neuronas.split('/')[2]), \n",
    "                out_features = 5 #número de neuronas de salida (número de etiquetas del problema)\n",
    "            )\n",
    "\n",
    "        def forward(self,x):\n",
    "            #en esta función es donde tiene lugar la computación (y la función invocada por defecto al ejecutar la red)\n",
    "            #siguiendo la estructura descrita en Ghosh et al. (con sus respectivas variaciones):\n",
    "\n",
    "            #primero una capa convolucional de tipo 1, con su consecuente activación PReLU y la capa de MaxPool\n",
    "            x = self.pool(self.activation(self.conv1(x)))\n",
    "            #una capa convolucional de tipo 2 con su correspondiente activación\n",
    "            x = self.activation(self.conv2_3(x))\n",
    "            #capa convolucional de tipo 2 con activación y MaxPool\n",
    "            x = self.pool(self.activation(self.conv2_3(x)))\n",
    "            #cuarta convolucional con activación\n",
    "            x = self.activation(self.conv4(x))\n",
    "            #quinta convolucional con activación y MaxPool\n",
    "            x = self.pool(self.activation(self.conv5(x)))\n",
    "            #3 capas convolucionales consecutivas de tipo 2 con su correspondiente activación\n",
    "            x = self.activation(self.conv6(x))\n",
    "            if capas_conv > 6:\n",
    "                x = self.activation(self.conv7_8_9(x))\n",
    "                x = self.activation(self.conv7_8_9(x))\n",
    "                #novena capa convolucional con activación y MaxPool\n",
    "                x = self.pool(self.activation(self.conv7_8_9(x)))\n",
    "                if capas_conv > 9:\n",
    "                    #se repite la misma estructura de 3 capas convolucionales con activación y una última con activación y MaxPool\n",
    "                    x = self.activation(self.conv10(x))\n",
    "                    x = self.activation(self.conv11_12_13(x))\n",
    "                    x = self.activation(self.conv11_12_13(x))\n",
    "                    x = self.pool(self.activation(self.conv11_12_13(x)))\n",
    "            #aplanamos la salida, hasta convertirla de forma matricial a forma vectorial (sería la capa flatten)\n",
    "            x = x.view(-1,self.num_flat_features(x))#usamos una función propia de la clase para obtener el número de características\n",
    "            #aplicamos una primera red neuronal fully-connected, con la activación consecuente y la estrategia dropout para evitar el sobreentrenamiento\n",
    "            x = F.dropout(self.activation(self.fc1(x)))\n",
    "            #lo mismo sucede con la segunda capa fully-connected\n",
    "            x = F.dropout(self.activation(self.fc2(x)))\n",
    "            #y con la tercera\n",
    "            x = F.dropout(self.activation(self.fc3(x)))\n",
    "            #por último tiene lugar la capa de predicciones, que convierte las 512 neuronas de la tercera capa fully-connected en una salida de 5 neuronas (una por clase)\n",
    "            x = self.dense(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "        def num_flat_features(self,x):\n",
    "            #por último definimos la función que permite obtener el número de características de los tensores\n",
    "            size = x.size()[1:] #seleccionamos todas las dimensiones expcepto la primera (que son los batches)\n",
    "            num_features = 1\n",
    "            #va iterando y calcula el número de características de los datos (x)\n",
    "            for s in size:\n",
    "                num_features*=s\n",
    "            return num_features\n",
    "\n",
    "    #por último creamos una instancia de esta red\n",
    "    modelo = Ghosh()\n",
    "    #y la devolvemos\n",
    "    return modelo\n",
    "\n",
    "#una vez definida dicha función, debemos generar las iteraciones necesarias para crear todas las redes resultantes de las combinaciones\n",
    "#creamos un bucle para cada una de las características, uno por cada posible valor del número de capas\n",
    "for capas in [6,9,13]:\n",
    "    #otro para que recorra los posibles valores del parámetro filtros\n",
    "    for n_filtros in [1.0,0.5,2.0]:\n",
    "        #y uno último para el número de neuronas\n",
    "        for n_neuronas in ['256/1024/512','128/512/256','64/256/128','128/256/512','512/256/128']:\n",
    "            #para cada combinacion de los parámetros creamos el modelo\n",
    "            modelo = crea_Ghosh(capas,n_filtros,n_neuronas)\n",
    "            #definimos como loss la función de tipo cross entropy \n",
    "            criterion = nn.CrossEntropyLoss() \n",
    "            #en este caso el optimizador será la función Adam (ampliamente utilizada)\n",
    "            optimizer = torch.optim.Adam(params = modelo.parameters()) #dejamos el valor de learning-rate por defecto (0.001)\n",
    "            #previo al entrenamiento imprimimos por pantalla las características de la red, para poder identificar su entrenamiento\n",
    "            print('--------------------------------------')\n",
    "            print(f'Entrenamiento. Características:\\n  -Capas:{capas}\\n  -Filtros:{n_filtros}\\n  -Neuronas:{n_neuronas}\\n  -Early Stopping\\n')\n",
    "            #capturamos el tiempo antes del entrenamiento\n",
    "            inicio = time.time()\n",
    "            #entrenamos la red con 7 épocas de paciencia y guardamos los valores para poder representar las gráficas\n",
    "            acc,loss,val_acc,val_loss = entrena_val(modelo,epocas,7,train_loader,val_loader,optimizer,criterion)\n",
    "            #capturamos el tiempo tras el entrenamiento\n",
    "            fin = time.time()\n",
    "            \n",
    "            #guardamos las gráficas\n",
    "            guarda_graficas('OCT','Si','No','Si','RGB','Ghosh',capas,n_filtros,n_neuronas,acc,loss,val_acc,val_loss)\n",
    "            \n",
    "            #ponemos a prueba la red con el conjunto de iPhone usando la función tester y recogemos los resultados para obtener las métricas\n",
    "            y_true_iphone, y_pred_iphone, predictions_iphone = tester(modelo,test_i_loader)\n",
    "            #obtenemos las métricas usando la función importada obtiene_metricas, que no las muestra por pantalla\n",
    "            metricas_iphone = obtiene_metricas(y_true_iphone, y_pred_iphone, predictions_iphone)\n",
    "            #las mostramos por pantalla\n",
    "            print('\\n--------------------------------------')\n",
    "            print(f'Test. Características:\\n  -Capas:{capas}\\n  -Filtros:{n_filtros}\\n  -Neuronas:{n_neuronas}\\n  -Test:iphone')\n",
    "            print(f' - Matriz de confusión:\\n{metricas_iphone[0]}\\n - Accuracy:{metricas_iphone[1]}\\n - Balanced accuracy:{metricas_iphone[2]}\\n - F-score:{metricas_iphone[3]}\\n - Kappa:{metricas_iphone[4]}\\n - AUC:{metricas_iphone[5]}\\n - Tiempo:{(fin-inicio)/60} mins')\n",
    "            #escribimos las métricas (a excepción de la matriz de confusión) en el archivo Resultados.csv previamente creado\n",
    "            with open('Resultados.csv','a') as fd:\n",
    "                fd.write('\\n')\n",
    "                fd.write(f'OCT,Sí,No,Sí,RGB,Ghosh,{capas},{n_filtros},{n_neuronas},iphone,{metricas_iphone[1]},{metricas_iphone[2]},{metricas_iphone[3]},{metricas_iphone[4]},{metricas_iphone[5]},{(fin-inicio)/60}')\n",
    "                \n",
    "                \n",
    "            #ahora ponemos a prueba la red con el conjunto de Samsung usando la función tester y recogemos los resultados para obtener las métricas\n",
    "            y_true_samsung, y_pred_samsung, predictions_samsung = tester(modelo,test_S_loader)\n",
    "            #obtenemos las métricas usando la función importada obtiene_metricas, que no las muestra por pantalla\n",
    "            metricas_samsung = obtiene_metricas(y_true_samsung, y_pred_samsung, predictions_samsung)\n",
    "            #las mostramos por pantalla\n",
    "            print('\\n--------------------------------------')\n",
    "            print(f'Test. Características:\\n  -Capas:{capas}\\n  -Filtros:{n_filtros}\\n  -Neuronas:{n_neuronas}\\n  -Test:Samsung')\n",
    "            print(f' - Matriz de confusión:\\n{metricas_samsung[0]}\\n - Accuracy:{metricas_samsung[1]}\\n - Balanced accuracy:{metricas_samsung[2]}\\n - F-score:{metricas_samsung[3]}\\n - Kappa:{metricas_samsung[4]}\\n - AUC:{metricas_samsung[5]}\\n - Tiempo:{(fin-inicio)/60} mins')\n",
    "            #escribimos las métricas (a excepción de la matriz de confusión) en el archivo Resultados.csv previamente creado\n",
    "            with open('Resultados.csv','a') as fd:\n",
    "                fd.write('\\n')\n",
    "                fd.write(f'OCT,Sí,No,Sí,RGB,Ghosh,{capas},{n_filtros},{n_neuronas},Samsung,{metricas_samsung[1]},{metricas_samsung[2]},{metricas_samsung[3]},{metricas_samsung[4]},{metricas_samsung[5]},{(fin-inicio)/60}')\n",
    "                \n",
    "            #por último vamos a guardar el modelo, sus pesos y estado actual, por si se quisiera volver a emplear\n",
    "            #primero para ello debemos cambiar el String de filtros y neuronas para evitar los puntos y barras laterales\n",
    "            filtros_str = str(n_filtros).replace(\".\",\"punto\")\n",
    "            neuronas_str = str(n_neuronas).replace(\"/\",\"slash\")\n",
    "            torch.save(modelo.state_dict(), f'modelos/Ghosh/OCT_Sival_Noprep_Siinp_RGB_{capas}_{filtros_str}_{neuronas_str}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
